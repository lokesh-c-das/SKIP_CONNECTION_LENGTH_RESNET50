{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "from keras.layers import Add\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dName=\"CIFAR10\"):\n",
    "    dataset = None\n",
    "    num_classes = None\n",
    "    if dName == \"CIFAR10\":\n",
    "        num_classes = 10\n",
    "        dataset = tf.keras.datasets.cifar10.load_data()\n",
    "    if dName == \"CIFAR100\":\n",
    "        num_classes = 100\n",
    "        dataset = tf.keras.datasets.cifar100.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = dataset\n",
    "    # Convert target value to categorical values\n",
    "    # One-hot-encoded target values\n",
    "    y_train = to_categorical(y_train,num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return (X_train, y_train),(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding of target labels\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initial Convolutional layer which is common to all ResNet models.\n",
    "\"\"\"\n",
    "#Input : Input tensor\n",
    "#filter : No of Convolutional filters\n",
    "#stride : stride length \n",
    "#kernel_size : Convolutional filter size\n",
    "\n",
    "#NOTE : kernel size and stride length are 7 and 2 in resnet paper\n",
    "\n",
    "# Kernel size of 3 and stride length of 2 and 1 are tried for CIFAR-10 dataset because of low resolution of the images\n",
    "\n",
    "def initial_conv(Input, filters, stride = 1,kernel_size = 7):\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=(kernel_size,kernel_size), strides = (stride,stride), padding = \"same\")(Input)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Residual Block with projection shortcut to match the dimensions using 1*1 convolutions.\n",
    "\n",
    "Note : This is basic residual Block, here all the convolutions are of same size and the depth is kept constant\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Note : Stride 2 is used to downsample the image in CONV2,CONV3 and CONV4 blocks\n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "def expand_conv_basic_block(Input, filters, stride=1, dropout = 0.0):\n",
    "    Init = Input\n",
    "    \n",
    "    #First conv which is used to downsample the image\n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Optional Dropout layer\n",
    "    if(dropout > 0.0):\n",
    "        x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (1,1),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Projection shortcut to make skip connection(Paper terminology)\n",
    "    skip_conv = Conv2D(filters, kernel_size = (1,1),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    skip = BatchNormalization()(skip_conv)\n",
    "    \n",
    "    #Skip connection\n",
    "    x = Add()([x,skip])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Residual networks with basic Identity shortcuts\n",
    "\n",
    "\"\"\"\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "def normal_conv_basic_block(Input, filters, stride = 1, dropout = 0.0):\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Optional Dropout layer\n",
    "    if(dropout > 0.0):\n",
    "        x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Identity skip connection\n",
    "    x = Add()([x,Input])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Residual Block with projection shortcut to match the dimensions using 1*1 convolutions.\n",
    "\n",
    "Note : This is bottleneck residual block. Here first 1*1 convolution is used to reduce depth, followed by 3*3 \n",
    "        and last 1*1 is used to restore the depth\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Note : Stride 2 is used to downsample the image in CONV2,CONV3 and CONV4 blocks\n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "def expand_conv_bottleneck_block(Input,filters,stride=1,dropout = 0.0):\n",
    "    \n",
    "    #Contracting 1*1 conv\n",
    "    x = Conv2D(filters,kernel_size=(1,1),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #if(dropout > 0.0):\n",
    "     #   x = Dropout(dropout)(x)\n",
    "    \n",
    "    #Depth preserving 3*3 conv\n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (1,1),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #if(Dropout > 0.0):\n",
    "     #   x = Dropout(dropout)(x)\n",
    "    \n",
    "    #Expanding 1*1 Conv\n",
    "    x = Conv2D(filters*4,kernel_size=(1,1),strides = (1,1),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Projection shortcut\n",
    "    skip_conv = Conv2D(filters*4,kernel_size = (1,1), strides = (stride, stride),padding = \"same\")(Input)\n",
    "    skip = BatchNormalization()(skip_conv)\n",
    "    \n",
    "    #Skip connection\n",
    "    x = Add()([x,skip])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Residual networks with bottleneck Identity shortcuts\n",
    "\n",
    "\"\"\"\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "\n",
    "def normal_conv_bottleneck_block(Input, filters, stride = 1, dropout = 0.0):\n",
    "    #Contracting 1*1 conv\n",
    "    x = Conv2D(filters,kernel_size=(1,1),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #if(dropout > 0.0):\n",
    "     #   x = Dropout(dropout)(x)\n",
    "        \n",
    "    #Depth preserving 3*3 Conv\n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "   # if(Dropout > 0.0):\n",
    "    #    x = Dropout(dropout)(x)\n",
    "    \n",
    "    #Expanding 1*1 Conv\n",
    "    x = Conv2D(filters*4,kernel_size=(1,1),strides = (stride,stride),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Identity skip connection\n",
    "    x = Add()([x,Input])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function to Build ResNet using basic residual blocks.\n",
    "Used when the total no of layers are less than 50.\n",
    "\n",
    "\"\"\"\n",
    "#h = height of the image\n",
    "#w = width of the image\n",
    "#no_of_outputs = no of classification classes\n",
    "#r1 = No of times first conv block should be repeated\n",
    "#r2 = No of times second conv block should be repeated\n",
    "#r3 = No of times third conv block should be repeated\n",
    "#r4 = No of times fourth conv block should be repeated\n",
    "\n",
    "# first_conv_stride = stride which will be used for initial conv block\n",
    "# first_max_pool = boolean to decide to apply max pooling or not\n",
    "# first_conv_size = kernel size which will be used for initial conv block\n",
    "\n",
    "#NOTE : The above three parameters are used only for cifar 10 data set coz of it's low resolution. \n",
    "        #For ImageNet Dataset they can be left as default\n",
    "\n",
    "\n",
    "def build_basic_resnet(h, w, no_of_outputs, r1,r2,r3,r4, first_conv_stride = 2, first_max_pool = True,first_conv_kernel_size = 7):\n",
    "    \n",
    "    #Creating input tensor\n",
    "    inputs = Input(shape = (h,w,3), name = \"image_input\")\n",
    "    \n",
    "    # Inital Conv block\n",
    "    x = initial_conv(inputs,64,first_conv_stride,first_conv_kernel_size)\n",
    "    \n",
    "    #Optional Max pooling layer\n",
    "    if(first_max_pool):\n",
    "        x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "\n",
    "    #Expanding block1 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,64,1)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv1\n",
    "    for i in range(r1-1):\n",
    "        x = normal_conv_basic_block(x,64)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block2 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,128,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv2\n",
    "    for i in range(r2-1):\n",
    "        x = normal_conv_basic_block(x,128)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block3 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,256,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv3\n",
    "    for i in range(r3-1):\n",
    "        x = normal_conv_basic_block(x,256)\n",
    "        x = Activation('relu')(x)\n",
    "          \n",
    "     #Expanding block4 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,512,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv3\n",
    "    for i in range(r4-1):\n",
    "        x = normal_conv_basic_block(x,512)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    shape = K.int_shape(x)\n",
    "    \n",
    "    #Average pooling layer\n",
    "    x = AveragePooling2D(pool_size=(shape[1], shape[2]),\n",
    "                                 strides=(1, 1))(x)\n",
    "   # x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    #Classifier Block\n",
    "    x = Dense(no_of_outputs,activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet 18\n",
    "model = build_basic_resnet(32,32,10,2,2,2,2,2,True,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet 34\n",
    "model = build_basic_resnet(32,32,10,3,4,6,3,2,True,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\"Resnet34.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function to Build ResNet using bottleneck residual blocks.\n",
    "Used when the total no of layers are more than 50.\n",
    "\n",
    "\"\"\"\n",
    "#h = height of the image\n",
    "#w = width of the image\n",
    "#no_of_outputs = no of classification classes\n",
    "#r1 = No of times first conv block should be repeated\n",
    "#r2 = No of times second conv block should be repeated\n",
    "#r3 = No of times third conv block should be repeated\n",
    "#r4 = No of times fourth conv block should be repeated\n",
    "\n",
    "# first_conv_stride = stride which will be used for initial conv block\n",
    "# first_max_pool = boolean to decide to apply max pooling or not\n",
    "# first_conv_size = kernel size which will be used for initial conv block\n",
    "\n",
    "#NOTE : The above three parameters are used only for cifar 10 data set coz of it's low resolution. \n",
    "        #For ImageNet Dataset they can be left as default\n",
    "\n",
    "\n",
    "def build_bottleneck_resnet(h, w, no_of_outputs, r1,r2,r3,r4, first_conv_stride = 2, first_max_pool = True,first_conv_kernel_size = 7):\n",
    "    \n",
    "    #Creating input tensor\n",
    "    inputs = Input(shape = (h,w,3), name = \"image_input\")\n",
    "    \n",
    "    # Inital Conv block\n",
    "    x = initial_conv(inputs,64,first_conv_stride,first_conv_kernel_size)\n",
    "    \n",
    "    #Optional Max pooling layer\n",
    "    if(first_max_pool):\n",
    "        x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "        \n",
    "    #Expanding block1 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,64,1)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv1\n",
    "    for i in range(r1-1):\n",
    "        x = normal_conv_bottleneck_block(x,64)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block2 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,128,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv2\n",
    "    for i in range(r2-1):\n",
    "        x = normal_conv_bottleneck_block(x,128)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block3 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,256,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv3\n",
    "    for i in range(r3-1):\n",
    "        x = normal_conv_bottleneck_block(x,256)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block4 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,512,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv4\n",
    "    for i in range(r4-1):\n",
    "        x = normal_conv_bottleneck_block(x,512)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    shape = K.int_shape(x)\n",
    "    \n",
    "    #Average pooling layer\n",
    "    x = AveragePooling2D(pool_size=(shape[1], shape[2]),\n",
    "                                 strides=(1, 1))(x)\n",
    "   # x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    #Classifier Block\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(no_of_outputs,activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 13:52:58.830965: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-12 13:52:58.831450: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#Normal ResNet50\n",
    "model = build_bottleneck_resnet(32,32,10,3,4,6,3,2,True,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 with stride 1 in Initial conv Block\n",
    "model = build_bottleneck_resnet(32,32,10,3,4,6,3,1,True,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\"ResNet50_stride1.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 without First Max pooling layer\n",
    "model = build_bottleneck_resnet(32,32,10,3,4,6,3,2,False,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\"ResNet50_without_maxpool.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 without First Max pooling layer and stride 1 in initial conv block\n",
    "model = build_bottleneck_resnet(32,32,10,3,4,6,3,1,False,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\"ResNet50_without_maxpool_and_stride1.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet101\n",
    "model = build_bottleneck_resnet(32,32,10,3,4,23,3,2,True,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\"ResNet101.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet152\n",
    "model = build_bottleneck_resnet(32,32,10,3,8,36,3,2,True,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\"ResNet152.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=\"Adam\",\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "csv_logger = CSVLogger('ResNet50_without_dropout_without_conv_without_pool.csv')\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=30)\n",
    "model_chekpoint = ModelCheckpoint(\"ResNet50_without_dropout_without_conv_without_pool.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Parameters\n",
    "batch_size = 64\n",
    "data_augmentation = True\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augmentation :\n",
    "    print(\"-------------Using Data augmentation------------\")\n",
    "     # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,verbose=1,validation_data=(x_test,y_test),callbacks = [lr_reducer,early_stopper,csv_logger,model_chekpoint])\n",
    "    \n",
    "else :\n",
    "    print(\"-----Not Using Data augmentation---------------\")\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size*4,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
