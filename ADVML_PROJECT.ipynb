{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Links\n",
    "# 1. https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
    "# 2. https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/\n",
    "# 3. https://towardsdatascience.com/resnets-for-cifar-10-e63e900524e0 (Understanding the resnet architecture for cifar10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model,load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D,Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dName=\"CIFAR10\"):\n",
    "    dataset = None\n",
    "    if dName == \"CIFAR10\":\n",
    "        dataset = tf.keras.datasets.cifar10.load_data()\n",
    "    if dName == \"CIFAR100\":\n",
    "        dataset = tf.keras.datasets.cifar100.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = dataset\n",
    "    # Convert target value to categorical values\n",
    "    # One-hot-encoded target values\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    return (X_train, y_train),(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describeDataset(X_train, y_train, X_test, y_test):\n",
    "    print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
    "    print('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImage(images=None):\n",
    "    if images.any():\n",
    "        # Plot a few images\n",
    "        for i in range(9):\n",
    "            plt.subplot(330+1+i)\n",
    "            plt.imshow(images[i])\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Error! File is empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeInput(X_train,X_test):\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train = X_train/255.0\n",
    "    X_test = X_test/255.0\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just for testing preprocessing steps\n",
    "def defineModel(classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def plotLearningCurve(history):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = load_dataset('CIFAR100')\n",
    "describeDataset(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayImage(X_train) # Need to pass a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = normalizeInput(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = defineModel(y_train.shape[1])\n",
    "history = model.fit(X_train,y_train,epochs=100, batch_size=64, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLearningCurve(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identityBlock(X, f, filters, stage, block):\n",
    "    k_initializer = glorot_uniform(seed=0)\n",
    "    conv_name = 'res'+str(stage)+block+'_branch'\n",
    "    bat_name = 'bn'+str(stage)+block+'_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2D(filters=F1,kernel_size=(1,1),strides =(1,1),padding='valid',name=conv_name+'2a',\n",
    "              kernel_initializer=k_initializer)(X)\n",
    "    X = BatchNormalization(axis=3,name=bat_name+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f),strides=(1,1),padding='same',name=conv_name+'2b',\n",
    "              kernel_initializer=k_initializer)(X)\n",
    "    X = BatchNormalization(axis=3,name=bat_name+'2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid',name=conv_name+'2c',\n",
    "              kernel_initializer=k_initializer)(X)\n",
    "    X = BatchNormalization(axis=3,name=bat_name+'2c')(X)\n",
    "    \n",
    "    X = Add()([X,X_skip])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionalBlock(X, f, filters, stage, block, s=2):\n",
    "    k_init = glorot_uniform(seed=0)\n",
    "    conv_name = 'res'+str(stage)+block+'_branch'\n",
    "    bat_name = 'bn'+str(stage)+block+'_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),name=conv_name+'2a',kernel_initializer=k_init)(X)\n",
    "    X = BatchNormalization(axis=3,name=bat_name+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f),strides=(1,1),padding='same', name=conv_name+'2b',kernel_initializer=k_init)(X)\n",
    "    X = BatchNormalization(axis=3,name=bat_name+'2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1),strides=(1,1),padding='valid',name=conv_name+'2c',kernel_initializer=k_init)(X)\n",
    "    X = BatchNormalization(axis=3,name=bat_name+'2c')(X)\n",
    "    \n",
    "    X_skip = Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s), padding='valid',name=conv_name+'1',\n",
    "                   kernel_initializer=k_init)(X_skip)\n",
    "    X_skip = BatchNormalization(axis=3,name=bat_name+'1')(X_skip)\n",
    "    \n",
    "    X = Add()([X, X_skip])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64,64,3), classes=6):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    \n",
    "    X = Conv2D(64,kernel_size=(7,7),strides=(2,2),name='conv1',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3,3),strides=(2,2))(X)\n",
    "    \n",
    "    X = convolutionalBlock(X, f=3, filters=[64,64,256],stage=2,block='a',s=1)\n",
    "    X = identityBlock(X,3,[64,64,256],stage=2,block='b')\n",
    "    X = identityBlock(X,3,[64,64,256],stage=2,block='c')\n",
    "    \n",
    "    \n",
    "    X = convolutionalBlock(X, f=3, filters=[128,128,512],stage=3,block='a',s=2)\n",
    "    X = identityBlock(X,3,[128,128,512],stage=3,block='b')\n",
    "    X = identityBlock(X,3,[128,128,512],stage=3,block='c')\n",
    "    X = identityBlock(X,3,[128,128,512],stage=3,block='d')\n",
    "   \n",
    "    \n",
    "    X = convolutionalBlock(X, f=3, filters=[256,256,1024],stage=4,block='a',s=2)\n",
    "    X = identityBlock(X,3,[256,256,1024],stage=4,block='b')\n",
    "    X = identityBlock(X,3,[256,256,1024],stage=4,block='c')\n",
    "    X = identityBlock(X,3,[256,256,1024],stage=4,block='d')\n",
    "    X = identityBlock(X,3,[256,256,1024],stage=4,block='e')\n",
    "    X = identityBlock(X,3,[256,256,1024],stage=4,block='f')\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = convolutionalBlock(X, f=3, filters=[512,512,2048],stage=5,block='a',s=2)\n",
    "    X = identityBlock(X,3,[512,512,2048],stage=5,block='b')\n",
    "    X = identityBlock(X,3,[512,512,2048],stage=5,block='c')\n",
    "    \n",
    "    \n",
    "    X = AveragePooling2D((2,2),name='avg_pool')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax',name='fc'+str(classes),kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    model = Model(inputs=X_input,outputs=X, name='LResNet50')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64,64,3),classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs=2, batch_size=64, validation_data=(X_test, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
