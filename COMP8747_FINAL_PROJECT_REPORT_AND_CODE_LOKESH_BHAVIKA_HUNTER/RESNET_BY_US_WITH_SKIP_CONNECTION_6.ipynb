{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "RESNET_BY_US_WITH_SKIP_CONNECTION_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-T7ILCuImn"
      },
      "source": [
        "# Useful Links\n",
        "# 1. https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "# 2. https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/\n",
        "# 3. https://towardsdatascience.com/resnets-for-cifar-10-e63e900524e0 (Understanding the resnet architecture for cifar10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbYz2fluImp"
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N146yjbF6YMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf2e7b3-271d-4d7e-cc8d-6457d25492cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "PATH = '/content/drive/MyDrive/PhD Studies/fall21/ADVML/results/skip6/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6OuColuImq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f122a8f-5205-4ae0-fb58-26a144804230"
      },
      "source": [
        "# Load necessary libraries\n",
        "for i in range(5):\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  #import cv2\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import backend as K\n",
        "  from tensorflow.keras.optimizers import SGD, Adam\n",
        "  #from google.colab.patches import cv2_imshow\n",
        "  from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "  from tensorflow.keras.models import Sequential, Model,load_model\n",
        "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "  from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D,Dropout\n",
        "  from tensorflow.keras.preprocessing import image\n",
        "  from tensorflow.keras.initializers import glorot_uniform\n",
        "  from matplotlib import pyplot as plt\n",
        "  from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "\n",
        "\n",
        "  def load_dataset(dName=\"CIFAR10\"):\n",
        "      dataset = None\n",
        "      num_classes = None\n",
        "      if dName == \"CIFAR10\":\n",
        "          num_classes = 10\n",
        "          dataset = tf.keras.datasets.cifar10.load_data()\n",
        "      if dName == \"CIFAR100\":\n",
        "          num_classes = 100\n",
        "          dataset = tf.keras.datasets.cifar100.load_data()\n",
        "      (X_train, y_train), (X_test, y_test) = dataset\n",
        "      # Convert target value to categorical values\n",
        "      # One-hot-encoded target values\n",
        "      y_train = to_categorical(y_train,num_classes)\n",
        "      y_test = to_categorical(y_test, num_classes)\n",
        "      \n",
        "      return (X_train, y_train),(X_test, y_test)\n",
        "  def divideDataset(X_train, y_train, X_test,y_test):\n",
        "      dataLength = X_train.shape[0]\n",
        "      trainLen=0\n",
        "      dataTrain = []\n",
        "      dataTest = []\n",
        "      percent = 0.2\n",
        "      while(trainLen<dataLength):\n",
        "          trainLen = int(X_train.shape[0]*percent)\n",
        "          #print(X_train[:trainLen].shape)\n",
        "          train = (X_train[:trainLen],y_train[:trainLen])\n",
        "          retriveLen = int(X_test.shape[0]*percent)\n",
        "          test = (X_test[:retriveLen],y_test[:retriveLen])\n",
        "          #print(tuple(train))\n",
        "          dataTrain.append(train)\n",
        "          dataTest.append(test)\n",
        "          #print(\"\\n\")\n",
        "          percent +=0.2\n",
        "      return dataTrain, dataTest\n",
        "  (X_train, y_train),(X_test, y_test) = load_dataset()\n",
        "  dataTrain, dataTest = divideDataset(X_train, y_train, X_test, y_test) # this contains the list of 5 different datasets\n",
        "  def normalizeInput(X_train,X_test):\n",
        "      X_train = X_train.astype('float32')\n",
        "      X_test = X_test.astype('float32')\n",
        "      mean = np.mean(X_train, axis=(0,1,2,3))\n",
        "      std = np.std(X_train,axis=(0,1,2,3))\n",
        "      X_train = (X_train-mean)/(std+1e-7)\n",
        "      X_test = (X_test-mean)/(std+1e-7)\n",
        "      \n",
        "      return X_train, X_test\n",
        "  ##### Include Little Data Augmentation \n",
        "  '''\n",
        "  batch_size = 64 # try several values\n",
        "\n",
        "  train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2, \n",
        "                                                                  width_shift_range=0.1, \n",
        "                                                                  height_shift_range = 0.1, \n",
        "                                                                  horizontal_flip=True)\n",
        "  \n",
        "  valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "  train_set_conv = train_DataGen.flow(X_train, y_train, batch_size=batch_size) # train_lab is categorical \n",
        "  valid_set_conv = valid_datagen.flow(X_test, y_test, batch_size=batch_size) # so as valid_lab\n",
        "  '''\n",
        "  X_train, X_test = normalizeInput(dataTrain[0][0], dataTest[0][0])\n",
        "  y_train = dataTrain[0][1]\n",
        "  y_test = dataTest[0][1]\n",
        "  # ResNet Implementation\n",
        "  # Code Link: https://github.com/Gurupradeep/CIFAR-10-Object-Recognition-in-Images/blob/master/Models/ResNet.ipynb\n",
        "  \n",
        "  def dataAugmentation():\n",
        "    datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "          height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "          horizontal_flip=False,  # randomly flip images\n",
        "          vertical_flip=False)  # randomly flip images\n",
        "    datagen.fit(X_train)\n",
        "    return datagen\n",
        "  daug = dataAugmentation()\n",
        "  \n",
        "  # RESNET50 WITH SKIP CONNECTION 6: Implemented by Lokesh\n",
        "  def createResnetWithSkip6(x, f,k, s,p,counter):\n",
        "    '''\n",
        "    Argument\n",
        "    x - input\n",
        "    f - filter_size\n",
        "    k - kernel size\n",
        "    s - stride\n",
        "    p - padding\n",
        "    '''\n",
        "    block_name = 'stage_2'+counter\n",
        "    x_skip = x\n",
        "    #print(\"Recevied Input at Stage ->: \"+counter, x.shape)\n",
        "    layers = len(f)\n",
        "    for i in range(layers):\n",
        "      x = Conv2D(f[i],kernel_size=(k[i],k[i]),strides=(s[i],s[i]),padding=p[i])(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "    x = Conv2D(f[layers-1],kernel_size=(k[layers-1],k[layers-1]),strides=(s[layers-1],s[layers-1]),padding=p[layers-1],name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    #print(x.shape)\n",
        "\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "\n",
        "    x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"Stage 2:\", (x_skip.shape,x.shape))\n",
        "\n",
        "    return x\n",
        "\n",
        "  def resnet50():\n",
        "    inputs = Input(shape = (32,32,3), name = \"image_input\")\n",
        "    x = ZeroPadding2D((3,3))(inputs)\n",
        "    # Initial Convolutional block\n",
        "    \n",
        "    x = Conv2D(64, kernel_size=(7,7), strides = (2,2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    print(\"before Max pooling: \", x.shape)\n",
        "    x = MaxPooling2D((3,3),strides=(2,2))(x)\n",
        "    x = createResnetWithSkip6(x,[64,64,256,64,64,256],[1,3,1,1,3,1],[1,1,1,1,1,1],['valid','same','valid','valid','same','valid'],'1')\n",
        "    x = createResnetWithSkip6(x,[64,64,256,128,128,512],[1,3,1,1,3,1],[1,1,1,2,1,1],['valid','same','valid','valid','same','valid'],'2')\n",
        "    x = createResnetWithSkip6(x,[128,128,512,128,128,512],[1,3,1,1,3,1],[1,1,1,1,1,1],['valid','same','valid','valid','same','valid'],'3')\n",
        "    x = createResnetWithSkip6(x,[128,128,512,256,256,1024],[1,3,1,1,3,1],[1,1,1,2,1,1],['valid','same','valid','valid','same','valid'],'4')\n",
        "    x = createResnetWithSkip6(x,[256,256,1024,256,256,1024],[1,3,1,1,3,1],[1,1,1,1,1,1],['valid','same','valid','valid','same','valid'],'5')\n",
        "    x = createResnetWithSkip6(x,[256,256,1024,256,256,1024],[1,3,1,1,3,1],[1,1,1,1,1,1],['valid','same','valid','valid','same','valid'],'6')\n",
        "    x = createResnetWithSkip6(x,[256,256,1024,512,512,2048],[1,3,1,1,3,1],[1,1,1,2,1,1],['valid','same','valid','valid','same','valid'],'7')\n",
        "    x = createResnetWithSkip6(x,[512,512,2048,512,512,2048],[1,3,1,1,3,1],[1,1,1,1,1,1],['valid','same','valid','valid','same','valid'],'8')\n",
        "    x = AveragePooling2D((2,2),padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(10,activation='softmax')(x)\n",
        "    model = Model(inputs=inputs,outputs=x, name='LResNet50')\n",
        "    #print(x.shape)\n",
        "    return model\n",
        "\n",
        "  model = resnet50()\n",
        "  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  #model.summary()\n",
        "  \n",
        "  X_train, X_test = normalizeInput(dataTrain[i][0], dataTest[i][0])\n",
        "  y_train = dataTrain[i][1]\n",
        "  y_test = dataTest[i][1]\n",
        "  epochs = 300\n",
        "  batch_size = 1024\n",
        "  earlyStop = EarlyStopping(monitor='loss',patience=5,mode='auto')\n",
        "  csvLogger = CSVLogger('/content/drive/MyDrive/PhD Studies/fall21/ADVML/results/skip6/'+str(i)+'.csv')\n",
        "  '''history = model.fit(daug.flow(X_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                          epochs=epochs,verbose=1,validation_data=(X_test,y_test),callbacks=[csvLogger,earlyStop])'''\n",
        "  history = model.fit(X_train,y_train, epochs=300,batch_size=1024,validation_data=(X_test,y_test),verbose=1, callbacks=[csvLogger,earlyStop])\n",
        "\n",
        "\n",
        "\n",
        "  import gc\n",
        "  del model\n",
        "  gc.collect()\n",
        "  K.clear_session()\n",
        "  tf.compat.v1.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before Max pooling:  (None, 16, 16, 64)\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 16s 868ms/step - loss: 3.2466 - accuracy: 0.1330 - val_loss: 2.3098 - val_accuracy: 0.1160\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 6s 650ms/step - loss: 2.1886 - accuracy: 0.2136 - val_loss: 2.2876 - val_accuracy: 0.1370\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 2.0154 - accuracy: 0.2352 - val_loss: 2.2711 - val_accuracy: 0.1585\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 6s 677ms/step - loss: 1.9594 - accuracy: 0.2637 - val_loss: 2.2651 - val_accuracy: 0.1635\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 6s 669ms/step - loss: 1.9081 - accuracy: 0.2845 - val_loss: 2.2607 - val_accuracy: 0.1570\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 6s 675ms/step - loss: 1.8775 - accuracy: 0.2939 - val_loss: 2.2765 - val_accuracy: 0.1075\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 6s 658ms/step - loss: 1.8205 - accuracy: 0.3174 - val_loss: 2.2742 - val_accuracy: 0.1165\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 6s 668ms/step - loss: 1.7859 - accuracy: 0.3356 - val_loss: 2.2763 - val_accuracy: 0.1150\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 6s 665ms/step - loss: 1.7548 - accuracy: 0.3508 - val_loss: 2.2844 - val_accuracy: 0.1150\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 6s 691ms/step - loss: 1.7061 - accuracy: 0.3763 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 6s 662ms/step - loss: 1.6663 - accuracy: 0.3925 - val_loss: 2.2853 - val_accuracy: 0.1200\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 6s 681ms/step - loss: 1.6272 - accuracy: 0.4018 - val_loss: 2.2824 - val_accuracy: 0.1615\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 6s 658ms/step - loss: 1.6004 - accuracy: 0.4137 - val_loss: 2.2920 - val_accuracy: 0.1135\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 6s 690ms/step - loss: 1.5789 - accuracy: 0.4253 - val_loss: 2.2900 - val_accuracy: 0.1320\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 6s 671ms/step - loss: 1.5463 - accuracy: 0.4361 - val_loss: 2.2734 - val_accuracy: 0.1295\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 6s 675ms/step - loss: 1.5278 - accuracy: 0.4471 - val_loss: 2.2215 - val_accuracy: 0.1400\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 6s 662ms/step - loss: 1.4911 - accuracy: 0.4613 - val_loss: 2.2229 - val_accuracy: 0.1255\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 6s 656ms/step - loss: 1.4570 - accuracy: 0.4719 - val_loss: 2.2260 - val_accuracy: 0.1090\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 6s 657ms/step - loss: 1.4626 - accuracy: 0.4670 - val_loss: 2.2764 - val_accuracy: 0.1400\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 6s 664ms/step - loss: 1.3908 - accuracy: 0.4948 - val_loss: 2.2571 - val_accuracy: 0.1460\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 6s 670ms/step - loss: 1.3697 - accuracy: 0.5041 - val_loss: 2.2432 - val_accuracy: 0.1710\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 6s 664ms/step - loss: 1.3427 - accuracy: 0.5120 - val_loss: 2.1602 - val_accuracy: 0.2225\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.3344 - accuracy: 0.5234 - val_loss: 2.0824 - val_accuracy: 0.2385\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 6s 646ms/step - loss: 1.3052 - accuracy: 0.5359 - val_loss: 2.1453 - val_accuracy: 0.2045\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.2906 - accuracy: 0.5334 - val_loss: 2.2186 - val_accuracy: 0.1945\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 6s 664ms/step - loss: 1.2807 - accuracy: 0.5419 - val_loss: 2.1083 - val_accuracy: 0.2350\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 6s 662ms/step - loss: 1.2620 - accuracy: 0.5528 - val_loss: 1.9963 - val_accuracy: 0.2770\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 6s 654ms/step - loss: 1.2229 - accuracy: 0.5608 - val_loss: 1.8451 - val_accuracy: 0.3330\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 6s 646ms/step - loss: 1.1723 - accuracy: 0.5777 - val_loss: 1.8801 - val_accuracy: 0.3065\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 6s 675ms/step - loss: 1.1495 - accuracy: 0.5968 - val_loss: 1.9486 - val_accuracy: 0.3245\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 6s 657ms/step - loss: 1.1271 - accuracy: 0.6026 - val_loss: 2.0063 - val_accuracy: 0.3305\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 6s 649ms/step - loss: 1.1031 - accuracy: 0.6141 - val_loss: 1.8689 - val_accuracy: 0.3575\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 6s 671ms/step - loss: 1.0641 - accuracy: 0.6150 - val_loss: 1.7498 - val_accuracy: 0.3900\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 6s 661ms/step - loss: 1.0845 - accuracy: 0.6275 - val_loss: 1.6808 - val_accuracy: 0.4250\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 6s 678ms/step - loss: 1.0177 - accuracy: 0.6406 - val_loss: 1.7322 - val_accuracy: 0.4275\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 6s 658ms/step - loss: 1.0029 - accuracy: 0.6463 - val_loss: 1.7385 - val_accuracy: 0.4245\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 6s 696ms/step - loss: 0.9559 - accuracy: 0.6594 - val_loss: 1.8407 - val_accuracy: 0.4225\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 6s 659ms/step - loss: 0.9217 - accuracy: 0.6745 - val_loss: 1.7615 - val_accuracy: 0.4390\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 0.9348 - accuracy: 0.6766 - val_loss: 1.7615 - val_accuracy: 0.4380\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 6s 662ms/step - loss: 0.8923 - accuracy: 0.6932 - val_loss: 1.8776 - val_accuracy: 0.4255\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 6s 667ms/step - loss: 0.8522 - accuracy: 0.7004 - val_loss: 1.9097 - val_accuracy: 0.4435\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 0.8501 - accuracy: 0.7024 - val_loss: 1.9217 - val_accuracy: 0.4590\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 6s 673ms/step - loss: 0.8068 - accuracy: 0.7200 - val_loss: 2.0156 - val_accuracy: 0.4355\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 6s 664ms/step - loss: 0.7851 - accuracy: 0.7274 - val_loss: 1.9282 - val_accuracy: 0.4375\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 6s 665ms/step - loss: 0.7691 - accuracy: 0.7351 - val_loss: 1.9332 - val_accuracy: 0.4575\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 6s 685ms/step - loss: 0.7712 - accuracy: 0.7324 - val_loss: 1.9943 - val_accuracy: 0.4490\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 6s 647ms/step - loss: 0.7705 - accuracy: 0.7333 - val_loss: 2.1832 - val_accuracy: 0.4295\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 6s 661ms/step - loss: 0.7060 - accuracy: 0.7546 - val_loss: 2.1803 - val_accuracy: 0.4285\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 6s 655ms/step - loss: 0.6486 - accuracy: 0.7722 - val_loss: 2.1280 - val_accuracy: 0.4700\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 6s 655ms/step - loss: 0.6818 - accuracy: 0.7591 - val_loss: 2.0997 - val_accuracy: 0.4600\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 6s 654ms/step - loss: 0.6336 - accuracy: 0.7827 - val_loss: 2.2702 - val_accuracy: 0.4545\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 6s 681ms/step - loss: 0.6171 - accuracy: 0.7859 - val_loss: 2.4986 - val_accuracy: 0.4365\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 6s 648ms/step - loss: 0.6187 - accuracy: 0.7882 - val_loss: 2.3637 - val_accuracy: 0.4470\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 0.5882 - accuracy: 0.7979 - val_loss: 2.3626 - val_accuracy: 0.4665\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 6s 654ms/step - loss: 0.5786 - accuracy: 0.8070 - val_loss: 2.4331 - val_accuracy: 0.4605\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 0.5589 - accuracy: 0.8111 - val_loss: 2.3362 - val_accuracy: 0.4910\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 6s 643ms/step - loss: 0.5369 - accuracy: 0.8181 - val_loss: 2.4693 - val_accuracy: 0.4720\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 0.5504 - accuracy: 0.8084 - val_loss: 2.4707 - val_accuracy: 0.4510\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 6s 673ms/step - loss: 0.5303 - accuracy: 0.8201 - val_loss: 2.5133 - val_accuracy: 0.4540\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 6s 647ms/step - loss: 0.5082 - accuracy: 0.8278 - val_loss: 2.6603 - val_accuracy: 0.4550\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 6s 654ms/step - loss: 0.4862 - accuracy: 0.8323 - val_loss: 2.8269 - val_accuracy: 0.4540\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 6s 633ms/step - loss: 0.4955 - accuracy: 0.8266 - val_loss: 3.2862 - val_accuracy: 0.4685\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 6s 643ms/step - loss: 0.4561 - accuracy: 0.8466 - val_loss: 3.2399 - val_accuracy: 0.4400\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 6s 639ms/step - loss: 0.4420 - accuracy: 0.8482 - val_loss: 2.9087 - val_accuracy: 0.4560\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 6s 655ms/step - loss: 0.4507 - accuracy: 0.8469 - val_loss: 2.7429 - val_accuracy: 0.4690\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 6s 633ms/step - loss: 0.3997 - accuracy: 0.8627 - val_loss: 2.6192 - val_accuracy: 0.4725\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 6s 630ms/step - loss: 0.3986 - accuracy: 0.8669 - val_loss: 2.7818 - val_accuracy: 0.4755\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 6s 673ms/step - loss: 0.4344 - accuracy: 0.8513 - val_loss: 2.9679 - val_accuracy: 0.4500\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 6s 659ms/step - loss: 0.4322 - accuracy: 0.8554 - val_loss: 2.6574 - val_accuracy: 0.4700\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 6s 698ms/step - loss: 0.4065 - accuracy: 0.8610 - val_loss: 2.7025 - val_accuracy: 0.4690\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 7s 714ms/step - loss: 0.3688 - accuracy: 0.8726 - val_loss: 2.8822 - val_accuracy: 0.4605\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 6s 680ms/step - loss: 0.3461 - accuracy: 0.8791 - val_loss: 2.7150 - val_accuracy: 0.4865\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 6s 657ms/step - loss: 0.3194 - accuracy: 0.8924 - val_loss: 2.7766 - val_accuracy: 0.4715\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 6s 692ms/step - loss: 0.3363 - accuracy: 0.8822 - val_loss: 2.8042 - val_accuracy: 0.4580\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 6s 696ms/step - loss: 0.3208 - accuracy: 0.8920 - val_loss: 2.8285 - val_accuracy: 0.4720\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 6s 655ms/step - loss: 0.2900 - accuracy: 0.9004 - val_loss: 2.9244 - val_accuracy: 0.4750\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 6s 667ms/step - loss: 0.2862 - accuracy: 0.9005 - val_loss: 2.9248 - val_accuracy: 0.4820\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 0.3150 - accuracy: 0.8943 - val_loss: 2.9959 - val_accuracy: 0.4750\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 6s 687ms/step - loss: 0.2820 - accuracy: 0.9046 - val_loss: 3.4509 - val_accuracy: 0.4965\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 6s 655ms/step - loss: 0.2769 - accuracy: 0.9072 - val_loss: 3.2117 - val_accuracy: 0.4840\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 6s 657ms/step - loss: 0.2797 - accuracy: 0.9035 - val_loss: 2.7393 - val_accuracy: 0.4940\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 6s 633ms/step - loss: 0.2621 - accuracy: 0.9093 - val_loss: 3.0365 - val_accuracy: 0.4790\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 6s 646ms/step - loss: 0.2559 - accuracy: 0.9128 - val_loss: 3.0637 - val_accuracy: 0.4770\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 6s 647ms/step - loss: 0.2401 - accuracy: 0.9181 - val_loss: 2.7571 - val_accuracy: 0.4745\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 6s 640ms/step - loss: 0.2255 - accuracy: 0.9225 - val_loss: 2.8970 - val_accuracy: 0.4610\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 6s 664ms/step - loss: 0.2457 - accuracy: 0.9168 - val_loss: 2.5756 - val_accuracy: 0.4835\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 6s 651ms/step - loss: 0.2197 - accuracy: 0.9266 - val_loss: 2.8098 - val_accuracy: 0.4795\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 6s 648ms/step - loss: 0.2466 - accuracy: 0.9168 - val_loss: 2.8949 - val_accuracy: 0.4805\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 6s 646ms/step - loss: 0.2708 - accuracy: 0.9115 - val_loss: 2.7310 - val_accuracy: 0.4870\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 6s 628ms/step - loss: 0.2519 - accuracy: 0.9215 - val_loss: 3.0039 - val_accuracy: 0.4975\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 6s 641ms/step - loss: 0.2221 - accuracy: 0.9248 - val_loss: 4.2152 - val_accuracy: 0.4920\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 6s 644ms/step - loss: 0.2277 - accuracy: 0.9257 - val_loss: 9.0149 - val_accuracy: 0.4730\n",
            "before Max pooling:  (None, 16, 16, 64)\n",
            "Epoch 1/300\n",
            "19/19 [==============================] - 21s 727ms/step - loss: 2.7291 - accuracy: 0.1708 - val_loss: 2.2724 - val_accuracy: 0.1445\n",
            "Epoch 2/300\n",
            "19/19 [==============================] - 12s 633ms/step - loss: 2.0036 - accuracy: 0.2600 - val_loss: 2.4092 - val_accuracy: 0.1238\n",
            "Epoch 3/300\n",
            "19/19 [==============================] - 12s 617ms/step - loss: 1.8738 - accuracy: 0.3130 - val_loss: 2.5227 - val_accuracy: 0.1187\n",
            "Epoch 4/300\n",
            "19/19 [==============================] - 12s 617ms/step - loss: 1.7951 - accuracy: 0.3452 - val_loss: 2.4336 - val_accuracy: 0.1070\n",
            "Epoch 5/300\n",
            "19/19 [==============================] - 12s 618ms/step - loss: 1.7234 - accuracy: 0.3680 - val_loss: 2.4588 - val_accuracy: 0.1077\n",
            "Epoch 6/300\n",
            "19/19 [==============================] - 12s 633ms/step - loss: 1.6778 - accuracy: 0.3912 - val_loss: 2.4831 - val_accuracy: 0.1303\n",
            "Epoch 7/300\n",
            "19/19 [==============================] - 12s 627ms/step - loss: 1.6313 - accuracy: 0.4091 - val_loss: 2.3735 - val_accuracy: 0.1347\n",
            "Epoch 8/300\n",
            "19/19 [==============================] - 12s 626ms/step - loss: 1.5889 - accuracy: 0.4237 - val_loss: 2.3521 - val_accuracy: 0.1138\n",
            "Epoch 9/300\n",
            "19/19 [==============================] - 12s 619ms/step - loss: 1.5530 - accuracy: 0.4433 - val_loss: 2.4393 - val_accuracy: 0.1117\n",
            "Epoch 10/300\n",
            "19/19 [==============================] - 12s 634ms/step - loss: 1.5067 - accuracy: 0.4570 - val_loss: 2.6093 - val_accuracy: 0.1135\n",
            "Epoch 11/300\n",
            "19/19 [==============================] - 12s 625ms/step - loss: 1.4710 - accuracy: 0.4662 - val_loss: 2.5386 - val_accuracy: 0.1295\n",
            "Epoch 12/300\n",
            "19/19 [==============================] - 12s 616ms/step - loss: 1.4298 - accuracy: 0.4822 - val_loss: 2.0726 - val_accuracy: 0.1750\n",
            "Epoch 13/300\n",
            "19/19 [==============================] - 12s 626ms/step - loss: 1.3978 - accuracy: 0.4911 - val_loss: 1.9560 - val_accuracy: 0.2623\n",
            "Epoch 14/300\n",
            "19/19 [==============================] - 12s 622ms/step - loss: 1.3660 - accuracy: 0.5054 - val_loss: 1.8160 - val_accuracy: 0.3255\n",
            "Epoch 15/300\n",
            "19/19 [==============================] - 12s 629ms/step - loss: 1.3510 - accuracy: 0.5162 - val_loss: 1.7972 - val_accuracy: 0.3483\n",
            "Epoch 16/300\n",
            "19/19 [==============================] - 12s 624ms/step - loss: 1.3115 - accuracy: 0.5279 - val_loss: 1.7209 - val_accuracy: 0.3945\n",
            "Epoch 17/300\n",
            "19/19 [==============================] - 12s 627ms/step - loss: 1.2861 - accuracy: 0.5347 - val_loss: 1.5115 - val_accuracy: 0.4487\n",
            "Epoch 18/300\n",
            "19/19 [==============================] - 12s 627ms/step - loss: 1.2581 - accuracy: 0.5504 - val_loss: 1.4445 - val_accuracy: 0.4770\n",
            "Epoch 19/300\n",
            "19/19 [==============================] - 12s 614ms/step - loss: 1.2336 - accuracy: 0.5608 - val_loss: 1.4559 - val_accuracy: 0.4748\n",
            "Epoch 20/300\n",
            "19/19 [==============================] - 12s 630ms/step - loss: 1.2070 - accuracy: 0.5663 - val_loss: 1.4163 - val_accuracy: 0.4913\n",
            "Epoch 21/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 1.1934 - accuracy: 0.5811 - val_loss: 1.5069 - val_accuracy: 0.4925\n",
            "Epoch 22/300\n",
            "19/19 [==============================] - 12s 621ms/step - loss: 1.1542 - accuracy: 0.5884 - val_loss: 1.5425 - val_accuracy: 0.4875\n",
            "Epoch 23/300\n",
            "19/19 [==============================] - 12s 629ms/step - loss: 1.1104 - accuracy: 0.6034 - val_loss: 1.5088 - val_accuracy: 0.4992\n",
            "Epoch 24/300\n",
            "19/19 [==============================] - 12s 621ms/step - loss: 1.0857 - accuracy: 0.6100 - val_loss: 1.5372 - val_accuracy: 0.4900\n",
            "Epoch 25/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 1.0583 - accuracy: 0.6233 - val_loss: 1.5956 - val_accuracy: 0.4985\n",
            "Epoch 26/300\n",
            "19/19 [==============================] - 12s 629ms/step - loss: 1.0176 - accuracy: 0.6332 - val_loss: 1.5096 - val_accuracy: 0.5215\n",
            "Epoch 27/300\n",
            "19/19 [==============================] - 12s 629ms/step - loss: 1.0123 - accuracy: 0.6333 - val_loss: 1.6644 - val_accuracy: 0.5077\n",
            "Epoch 28/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 0.9843 - accuracy: 0.6503 - val_loss: 1.6805 - val_accuracy: 0.5045\n",
            "Epoch 29/300\n",
            "19/19 [==============================] - 12s 625ms/step - loss: 0.9733 - accuracy: 0.6520 - val_loss: 1.5922 - val_accuracy: 0.5390\n",
            "Epoch 30/300\n",
            "19/19 [==============================] - 12s 634ms/step - loss: 0.9454 - accuracy: 0.6658 - val_loss: 1.6072 - val_accuracy: 0.5230\n",
            "Epoch 31/300\n",
            "19/19 [==============================] - 12s 630ms/step - loss: 0.9191 - accuracy: 0.6716 - val_loss: 1.7514 - val_accuracy: 0.5070\n",
            "Epoch 32/300\n",
            "19/19 [==============================] - 12s 641ms/step - loss: 0.9055 - accuracy: 0.6804 - val_loss: 1.8783 - val_accuracy: 0.5173\n",
            "Epoch 33/300\n",
            "19/19 [==============================] - 12s 625ms/step - loss: 0.8761 - accuracy: 0.6920 - val_loss: 1.7265 - val_accuracy: 0.5182\n",
            "Epoch 34/300\n",
            "19/19 [==============================] - 12s 628ms/step - loss: 0.8585 - accuracy: 0.6997 - val_loss: 1.8397 - val_accuracy: 0.5188\n",
            "Epoch 35/300\n",
            "19/19 [==============================] - 12s 635ms/step - loss: 0.8235 - accuracy: 0.7091 - val_loss: 1.8103 - val_accuracy: 0.5150\n",
            "Epoch 36/300\n",
            "19/19 [==============================] - 12s 628ms/step - loss: 0.8231 - accuracy: 0.7098 - val_loss: 1.8922 - val_accuracy: 0.5232\n",
            "Epoch 37/300\n",
            "19/19 [==============================] - 12s 629ms/step - loss: 0.8312 - accuracy: 0.7114 - val_loss: 1.9616 - val_accuracy: 0.4975\n",
            "Epoch 38/300\n",
            "19/19 [==============================] - 12s 625ms/step - loss: 0.8669 - accuracy: 0.7025 - val_loss: 2.2299 - val_accuracy: 0.5035\n",
            "Epoch 39/300\n",
            "19/19 [==============================] - 12s 631ms/step - loss: 0.8211 - accuracy: 0.7199 - val_loss: 2.1261 - val_accuracy: 0.5165\n",
            "Epoch 40/300\n",
            "19/19 [==============================] - 12s 639ms/step - loss: 0.7941 - accuracy: 0.7234 - val_loss: 1.9446 - val_accuracy: 0.5130\n",
            "Epoch 41/300\n",
            "19/19 [==============================] - 12s 639ms/step - loss: 0.7572 - accuracy: 0.7360 - val_loss: 1.8553 - val_accuracy: 0.5320\n",
            "Epoch 42/300\n",
            "19/19 [==============================] - 12s 644ms/step - loss: 0.7593 - accuracy: 0.7347 - val_loss: 1.9006 - val_accuracy: 0.5195\n",
            "Epoch 43/300\n",
            "19/19 [==============================] - 12s 644ms/step - loss: 0.6975 - accuracy: 0.7577 - val_loss: 2.0163 - val_accuracy: 0.5238\n",
            "Epoch 44/300\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 0.6781 - accuracy: 0.7655 - val_loss: 1.9326 - val_accuracy: 0.5370\n",
            "Epoch 45/300\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 0.6654 - accuracy: 0.7674 - val_loss: 2.7367 - val_accuracy: 0.4563\n",
            "Epoch 46/300\n",
            "19/19 [==============================] - 13s 654ms/step - loss: 0.7802 - accuracy: 0.7286 - val_loss: 10.7727 - val_accuracy: 0.4198\n",
            "Epoch 47/300\n",
            "19/19 [==============================] - 12s 645ms/step - loss: 0.6874 - accuracy: 0.7549 - val_loss: 2.9676 - val_accuracy: 0.5242\n",
            "Epoch 48/300\n",
            "19/19 [==============================] - 13s 659ms/step - loss: 0.6164 - accuracy: 0.7803 - val_loss: 2.1624 - val_accuracy: 0.5140\n",
            "Epoch 49/300\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 0.5746 - accuracy: 0.7981 - val_loss: 2.2313 - val_accuracy: 0.5385\n",
            "Epoch 50/300\n",
            "19/19 [==============================] - 12s 641ms/step - loss: 0.5768 - accuracy: 0.7999 - val_loss: 2.7559 - val_accuracy: 0.5472\n",
            "Epoch 51/300\n",
            "19/19 [==============================] - 12s 648ms/step - loss: 0.5349 - accuracy: 0.8162 - val_loss: 2.0745 - val_accuracy: 0.5425\n",
            "Epoch 52/300\n",
            "19/19 [==============================] - 13s 656ms/step - loss: 0.5334 - accuracy: 0.8107 - val_loss: 1.8645 - val_accuracy: 0.5585\n",
            "Epoch 53/300\n",
            "19/19 [==============================] - 12s 645ms/step - loss: 0.5032 - accuracy: 0.8253 - val_loss: 1.9018 - val_accuracy: 0.5630\n",
            "Epoch 54/300\n",
            "19/19 [==============================] - 12s 649ms/step - loss: 0.4796 - accuracy: 0.8335 - val_loss: 1.8724 - val_accuracy: 0.5670\n",
            "Epoch 55/300\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 0.4548 - accuracy: 0.8417 - val_loss: 2.0665 - val_accuracy: 0.5527\n",
            "Epoch 56/300\n",
            "19/19 [==============================] - 12s 647ms/step - loss: 0.4672 - accuracy: 0.8400 - val_loss: 1.8598 - val_accuracy: 0.5640\n",
            "Epoch 57/300\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 0.4271 - accuracy: 0.8539 - val_loss: 2.1433 - val_accuracy: 0.5552\n",
            "Epoch 58/300\n",
            "19/19 [==============================] - 12s 639ms/step - loss: 0.4205 - accuracy: 0.8542 - val_loss: 2.1192 - val_accuracy: 0.5420\n",
            "Epoch 59/300\n",
            "19/19 [==============================] - 13s 655ms/step - loss: 0.3939 - accuracy: 0.8627 - val_loss: 2.0687 - val_accuracy: 0.5497\n",
            "Epoch 60/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 0.3775 - accuracy: 0.8665 - val_loss: 2.0068 - val_accuracy: 0.5555\n",
            "Epoch 61/300\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 0.3910 - accuracy: 0.8650 - val_loss: 1.9830 - val_accuracy: 0.5562\n",
            "Epoch 62/300\n",
            "19/19 [==============================] - 12s 636ms/step - loss: 0.3565 - accuracy: 0.8750 - val_loss: 2.0082 - val_accuracy: 0.5715\n",
            "Epoch 63/300\n",
            "19/19 [==============================] - 12s 649ms/step - loss: 0.3584 - accuracy: 0.8751 - val_loss: 2.0357 - val_accuracy: 0.5683\n",
            "Epoch 64/300\n",
            "19/19 [==============================] - 13s 652ms/step - loss: 0.3392 - accuracy: 0.8841 - val_loss: 2.2303 - val_accuracy: 0.5555\n",
            "Epoch 65/300\n",
            "19/19 [==============================] - 12s 634ms/step - loss: 0.3288 - accuracy: 0.8833 - val_loss: 2.0987 - val_accuracy: 0.5625\n",
            "Epoch 66/300\n",
            "19/19 [==============================] - 12s 635ms/step - loss: 0.3179 - accuracy: 0.8913 - val_loss: 1.9821 - val_accuracy: 0.5640\n",
            "Epoch 67/300\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 0.3054 - accuracy: 0.8934 - val_loss: 2.2524 - val_accuracy: 0.5583\n",
            "Epoch 68/300\n",
            "19/19 [==============================] - 12s 619ms/step - loss: 0.3132 - accuracy: 0.8899 - val_loss: 2.1167 - val_accuracy: 0.5677\n",
            "Epoch 69/300\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 0.3191 - accuracy: 0.8878 - val_loss: 2.1000 - val_accuracy: 0.5705\n",
            "Epoch 70/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 0.2909 - accuracy: 0.9014 - val_loss: 2.3950 - val_accuracy: 0.5318\n",
            "Epoch 71/300\n",
            "19/19 [==============================] - 12s 626ms/step - loss: 0.2866 - accuracy: 0.9003 - val_loss: 2.3582 - val_accuracy: 0.5560\n",
            "Epoch 72/300\n",
            "19/19 [==============================] - 12s 624ms/step - loss: 0.2823 - accuracy: 0.8997 - val_loss: 2.1726 - val_accuracy: 0.5753\n",
            "Epoch 73/300\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 0.2852 - accuracy: 0.9028 - val_loss: 2.7786 - val_accuracy: 0.5395\n",
            "Epoch 74/300\n",
            "19/19 [==============================] - 12s 645ms/step - loss: 0.3081 - accuracy: 0.8959 - val_loss: 2.4202 - val_accuracy: 0.5552\n",
            "Epoch 75/300\n",
            "19/19 [==============================] - 12s 644ms/step - loss: 0.3046 - accuracy: 0.9001 - val_loss: 2.4093 - val_accuracy: 0.5555\n",
            "Epoch 76/300\n",
            "19/19 [==============================] - 12s 650ms/step - loss: 0.2768 - accuracy: 0.9049 - val_loss: 2.1420 - val_accuracy: 0.5673\n",
            "Epoch 77/300\n",
            "19/19 [==============================] - 12s 647ms/step - loss: 0.2632 - accuracy: 0.9077 - val_loss: 2.1374 - val_accuracy: 0.5732\n",
            "Epoch 78/300\n",
            "19/19 [==============================] - 12s 664ms/step - loss: 0.2713 - accuracy: 0.9047 - val_loss: 2.4084 - val_accuracy: 0.5660\n",
            "Epoch 79/300\n",
            "19/19 [==============================] - 12s 645ms/step - loss: 0.2499 - accuracy: 0.9145 - val_loss: 2.6791 - val_accuracy: 0.5605\n",
            "Epoch 80/300\n",
            "19/19 [==============================] - 12s 640ms/step - loss: 0.2497 - accuracy: 0.9166 - val_loss: 2.1337 - val_accuracy: 0.5663\n",
            "Epoch 81/300\n",
            "19/19 [==============================] - 12s 642ms/step - loss: 0.2521 - accuracy: 0.9117 - val_loss: 2.7882 - val_accuracy: 0.5395\n",
            "Epoch 82/300\n",
            "19/19 [==============================] - 12s 641ms/step - loss: 0.2378 - accuracy: 0.9197 - val_loss: 2.7112 - val_accuracy: 0.5483\n",
            "Epoch 83/300\n",
            "19/19 [==============================] - 12s 643ms/step - loss: 0.2353 - accuracy: 0.9229 - val_loss: 2.6247 - val_accuracy: 0.5425\n",
            "Epoch 84/300\n",
            "19/19 [==============================] - 12s 656ms/step - loss: 0.2497 - accuracy: 0.9158 - val_loss: 2.3005 - val_accuracy: 0.5667\n",
            "Epoch 85/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 0.2332 - accuracy: 0.9221 - val_loss: 2.2455 - val_accuracy: 0.5767\n",
            "Epoch 86/300\n",
            "19/19 [==============================] - 12s 646ms/step - loss: 0.2169 - accuracy: 0.9250 - val_loss: 2.1419 - val_accuracy: 0.5788\n",
            "Epoch 87/300\n",
            "19/19 [==============================] - 12s 643ms/step - loss: 0.2116 - accuracy: 0.9288 - val_loss: 2.4364 - val_accuracy: 0.5577\n",
            "Epoch 88/300\n",
            "19/19 [==============================] - 12s 646ms/step - loss: 0.2173 - accuracy: 0.9241 - val_loss: 2.1086 - val_accuracy: 0.5725\n",
            "Epoch 89/300\n",
            "19/19 [==============================] - 12s 644ms/step - loss: 0.2175 - accuracy: 0.9262 - val_loss: 2.1684 - val_accuracy: 0.5680\n",
            "Epoch 90/300\n",
            "19/19 [==============================] - 12s 640ms/step - loss: 0.2411 - accuracy: 0.9234 - val_loss: 2.4465 - val_accuracy: 0.5595\n",
            "Epoch 91/300\n",
            "19/19 [==============================] - 12s 645ms/step - loss: 0.2266 - accuracy: 0.9215 - val_loss: 2.1873 - val_accuracy: 0.5720\n",
            "Epoch 92/300\n",
            "19/19 [==============================] - 12s 647ms/step - loss: 0.2022 - accuracy: 0.9314 - val_loss: 2.2700 - val_accuracy: 0.5742\n",
            "Epoch 93/300\n",
            "19/19 [==============================] - 12s 644ms/step - loss: 0.1892 - accuracy: 0.9354 - val_loss: 2.2642 - val_accuracy: 0.5757\n",
            "Epoch 94/300\n",
            "19/19 [==============================] - 12s 650ms/step - loss: 0.1810 - accuracy: 0.9368 - val_loss: 2.2646 - val_accuracy: 0.5745\n",
            "Epoch 95/300\n",
            "19/19 [==============================] - 13s 662ms/step - loss: 0.1999 - accuracy: 0.9301 - val_loss: 2.1501 - val_accuracy: 0.5860\n",
            "Epoch 96/300\n",
            "19/19 [==============================] - 12s 647ms/step - loss: 0.1649 - accuracy: 0.9434 - val_loss: 2.1965 - val_accuracy: 0.5820\n",
            "Epoch 97/300\n",
            "19/19 [==============================] - 12s 647ms/step - loss: 0.1705 - accuracy: 0.9430 - val_loss: 2.2237 - val_accuracy: 0.5878\n",
            "Epoch 98/300\n",
            "19/19 [==============================] - 12s 649ms/step - loss: 0.1626 - accuracy: 0.9435 - val_loss: 3.7488 - val_accuracy: 0.5830\n",
            "Epoch 99/300\n",
            "19/19 [==============================] - 12s 669ms/step - loss: 0.1794 - accuracy: 0.9383 - val_loss: 2.6059 - val_accuracy: 0.5750\n",
            "Epoch 100/300\n",
            "19/19 [==============================] - 13s 656ms/step - loss: 0.1638 - accuracy: 0.9478 - val_loss: 2.2369 - val_accuracy: 0.5885\n",
            "Epoch 101/300\n",
            "19/19 [==============================] - 12s 658ms/step - loss: 0.1617 - accuracy: 0.9450 - val_loss: 2.4023 - val_accuracy: 0.5832\n",
            "Epoch 102/300\n",
            "19/19 [==============================] - 12s 639ms/step - loss: 0.1632 - accuracy: 0.9429 - val_loss: 2.5215 - val_accuracy: 0.5780\n",
            "Epoch 103/300\n",
            "19/19 [==============================] - 12s 632ms/step - loss: 0.1564 - accuracy: 0.9457 - val_loss: 2.2406 - val_accuracy: 0.5888\n",
            "Epoch 104/300\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 0.1655 - accuracy: 0.9437 - val_loss: 2.1839 - val_accuracy: 0.5855\n",
            "Epoch 105/300\n",
            "19/19 [==============================] - 12s 646ms/step - loss: 0.2042 - accuracy: 0.9321 - val_loss: 27.4188 - val_accuracy: 0.5013\n",
            "Epoch 106/300\n",
            "19/19 [==============================] - 12s 626ms/step - loss: 0.1943 - accuracy: 0.9330 - val_loss: 2.3102 - val_accuracy: 0.5807\n",
            "Epoch 107/300\n",
            "19/19 [==============================] - 12s 634ms/step - loss: 0.1721 - accuracy: 0.9420 - val_loss: 2.2491 - val_accuracy: 0.5830\n",
            "Epoch 108/300\n",
            "19/19 [==============================] - 12s 648ms/step - loss: 0.1710 - accuracy: 0.9418 - val_loss: 2.4332 - val_accuracy: 0.5665\n",
            "before Max pooling:  (None, 16, 16, 64)\n",
            "Epoch 1/300\n",
            "29/29 [==============================] - 29s 712ms/step - loss: 2.4817 - accuracy: 0.2159 - val_loss: 2.3507 - val_accuracy: 0.1380\n",
            "Epoch 2/300\n",
            "29/29 [==============================] - 19s 657ms/step - loss: 1.8832 - accuracy: 0.3125 - val_loss: 2.3667 - val_accuracy: 0.1228\n",
            "Epoch 3/300\n",
            "29/29 [==============================] - 19s 639ms/step - loss: 1.7743 - accuracy: 0.3594 - val_loss: 2.4318 - val_accuracy: 0.1398\n",
            "Epoch 4/300\n",
            "29/29 [==============================] - 19s 653ms/step - loss: 1.6906 - accuracy: 0.3903 - val_loss: 2.4555 - val_accuracy: 0.1283\n",
            "Epoch 5/300\n",
            "29/29 [==============================] - 19s 646ms/step - loss: 1.6378 - accuracy: 0.4137 - val_loss: 2.4586 - val_accuracy: 0.1382\n",
            "Epoch 6/300\n",
            "29/29 [==============================] - 19s 653ms/step - loss: 1.5731 - accuracy: 0.4348 - val_loss: 2.4612 - val_accuracy: 0.1428\n",
            "Epoch 7/300\n",
            "29/29 [==============================] - 19s 651ms/step - loss: 1.6160 - accuracy: 0.4299 - val_loss: 2.2689 - val_accuracy: 0.2360\n",
            "Epoch 8/300\n",
            "29/29 [==============================] - 19s 660ms/step - loss: 1.5425 - accuracy: 0.4506 - val_loss: 2.6121 - val_accuracy: 0.1953\n",
            "Epoch 9/300\n",
            "29/29 [==============================] - 19s 654ms/step - loss: 1.4677 - accuracy: 0.4741 - val_loss: 2.0928 - val_accuracy: 0.2995\n",
            "Epoch 10/300\n",
            "29/29 [==============================] - 19s 652ms/step - loss: 1.4305 - accuracy: 0.4881 - val_loss: 1.8714 - val_accuracy: 0.3602\n",
            "Epoch 11/300\n",
            "29/29 [==============================] - 19s 650ms/step - loss: 1.4010 - accuracy: 0.4994 - val_loss: 1.8640 - val_accuracy: 0.3685\n",
            "Epoch 12/300\n",
            "29/29 [==============================] - 19s 649ms/step - loss: 1.3667 - accuracy: 0.5144 - val_loss: 1.5285 - val_accuracy: 0.4615\n",
            "Epoch 13/300\n",
            "29/29 [==============================] - 19s 648ms/step - loss: 1.3191 - accuracy: 0.5263 - val_loss: 1.4220 - val_accuracy: 0.4895\n",
            "Epoch 14/300\n",
            "29/29 [==============================] - 19s 646ms/step - loss: 1.2872 - accuracy: 0.5413 - val_loss: 1.3782 - val_accuracy: 0.5148\n",
            "Epoch 15/300\n",
            "29/29 [==============================] - 19s 651ms/step - loss: 1.2530 - accuracy: 0.5549 - val_loss: 1.4136 - val_accuracy: 0.5190\n",
            "Epoch 16/300\n",
            "29/29 [==============================] - 19s 646ms/step - loss: 1.2346 - accuracy: 0.5603 - val_loss: 1.4493 - val_accuracy: 0.5307\n",
            "Epoch 17/300\n",
            "29/29 [==============================] - 19s 636ms/step - loss: 1.2020 - accuracy: 0.5733 - val_loss: 1.4422 - val_accuracy: 0.5178\n",
            "Epoch 18/300\n",
            "29/29 [==============================] - 19s 655ms/step - loss: 1.1762 - accuracy: 0.5839 - val_loss: 1.4460 - val_accuracy: 0.5260\n",
            "Epoch 19/300\n",
            "29/29 [==============================] - 19s 661ms/step - loss: 1.1523 - accuracy: 0.5931 - val_loss: 1.6135 - val_accuracy: 0.5242\n",
            "Epoch 20/300\n",
            "29/29 [==============================] - 19s 658ms/step - loss: 1.1135 - accuracy: 0.6061 - val_loss: 1.6526 - val_accuracy: 0.4963\n",
            "Epoch 21/300\n",
            "29/29 [==============================] - 19s 657ms/step - loss: 1.0947 - accuracy: 0.6111 - val_loss: 1.5681 - val_accuracy: 0.5145\n",
            "Epoch 22/300\n",
            "29/29 [==============================] - 19s 639ms/step - loss: 1.0897 - accuracy: 0.6103 - val_loss: 1.4624 - val_accuracy: 0.5370\n",
            "Epoch 23/300\n",
            "29/29 [==============================] - 19s 662ms/step - loss: 1.0313 - accuracy: 0.6335 - val_loss: 2.4934 - val_accuracy: 0.5227\n",
            "Epoch 24/300\n",
            "29/29 [==============================] - 19s 655ms/step - loss: 1.0099 - accuracy: 0.6411 - val_loss: 1.4033 - val_accuracy: 0.5510\n",
            "Epoch 25/300\n",
            "29/29 [==============================] - 19s 646ms/step - loss: 0.9807 - accuracy: 0.6510 - val_loss: 1.4997 - val_accuracy: 0.5402\n",
            "Epoch 26/300\n",
            "29/29 [==============================] - 18s 633ms/step - loss: 0.9645 - accuracy: 0.6560 - val_loss: 1.5525 - val_accuracy: 0.5538\n",
            "Epoch 27/300\n",
            "29/29 [==============================] - 19s 636ms/step - loss: 0.9130 - accuracy: 0.6766 - val_loss: 1.4695 - val_accuracy: 0.5675\n",
            "Epoch 28/300\n",
            "29/29 [==============================] - 19s 637ms/step - loss: 0.8903 - accuracy: 0.6810 - val_loss: 1.4541 - val_accuracy: 0.5705\n",
            "Epoch 29/300\n",
            "29/29 [==============================] - 18s 632ms/step - loss: 0.8726 - accuracy: 0.6903 - val_loss: 1.5571 - val_accuracy: 0.5675\n",
            "Epoch 30/300\n",
            "29/29 [==============================] - 19s 635ms/step - loss: 0.8496 - accuracy: 0.7014 - val_loss: 1.5028 - val_accuracy: 0.5667\n",
            "Epoch 31/300\n",
            "29/29 [==============================] - 19s 653ms/step - loss: 0.8069 - accuracy: 0.7146 - val_loss: 1.5303 - val_accuracy: 0.5700\n",
            "Epoch 32/300\n",
            "29/29 [==============================] - 19s 642ms/step - loss: 0.8100 - accuracy: 0.7127 - val_loss: 1.6062 - val_accuracy: 0.5753\n",
            "Epoch 33/300\n",
            "29/29 [==============================] - 19s 635ms/step - loss: 0.8024 - accuracy: 0.7174 - val_loss: 1.7114 - val_accuracy: 0.5647\n",
            "Epoch 34/300\n",
            "29/29 [==============================] - 19s 646ms/step - loss: 0.7973 - accuracy: 0.7226 - val_loss: 2.5688 - val_accuracy: 0.5088\n",
            "Epoch 35/300\n",
            "29/29 [==============================] - 19s 640ms/step - loss: 0.7713 - accuracy: 0.7270 - val_loss: 1.6417 - val_accuracy: 0.5757\n",
            "Epoch 36/300\n",
            "10/29 [=========>....................] - ETA: 9s - loss: 0.6980 - accuracy: 0.7563 "
          ]
        }
      ]
    }
  ]
}