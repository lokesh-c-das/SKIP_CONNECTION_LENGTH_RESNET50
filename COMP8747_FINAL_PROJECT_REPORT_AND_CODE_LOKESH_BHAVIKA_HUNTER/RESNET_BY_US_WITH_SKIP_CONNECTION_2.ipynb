{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "RESNET_BY_US_WITH_SKIP_CONNECTION_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-T7ILCuImn"
      },
      "source": [
        "# Useful Links\n",
        "# 1. https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "# 2. https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/\n",
        "# 3. https://towardsdatascience.com/resnets-for-cifar-10-e63e900524e0 (Understanding the resnet architecture for cifar10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbYz2fluImp"
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWEmihO6kwi",
        "outputId": "e94a68f3-7822-42fb-cac4-59885a2c1ebd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6OuColuImq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab67916b-b2cd-4bdb-c647-793e9de6aae8"
      },
      "source": [
        "# Load necessary libraries\n",
        "for i in range(5):\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  #import cv2\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import backend as K\n",
        "  from tensorflow.keras.optimizers import SGD, Adam\n",
        "  #from google.colab.patches import cv2_imshow\n",
        "  from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "  from tensorflow.keras.models import Sequential, Model,load_model\n",
        "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "  from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D,Dropout\n",
        "  from tensorflow.keras.preprocessing import image\n",
        "  from tensorflow.keras.initializers import glorot_uniform\n",
        "  from matplotlib import pyplot as plt\n",
        "  from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "\n",
        "\n",
        "  def load_dataset(dName=\"CIFAR10\"):\n",
        "      dataset = None\n",
        "      num_classes = None\n",
        "      if dName == \"CIFAR10\":\n",
        "          num_classes = 10\n",
        "          dataset = tf.keras.datasets.cifar10.load_data()\n",
        "      if dName == \"CIFAR100\":\n",
        "          num_classes = 100\n",
        "          dataset = tf.keras.datasets.cifar100.load_data()\n",
        "      (X_train, y_train), (X_test, y_test) = dataset\n",
        "      # Convert target value to categorical values\n",
        "      # One-hot-encoded target values\n",
        "      y_train = to_categorical(y_train,num_classes)\n",
        "      y_test = to_categorical(y_test, num_classes)\n",
        "      \n",
        "      return (X_train, y_train),(X_test, y_test)\n",
        "  def divideDataset(X_train, y_train, X_test,y_test):\n",
        "      dataLength = X_train.shape[0]\n",
        "      trainLen=0\n",
        "      dataTrain = []\n",
        "      dataTest = []\n",
        "      percent = 0.2\n",
        "      while(trainLen<dataLength):\n",
        "          trainLen = int(X_train.shape[0]*percent)\n",
        "          #print(X_train[:trainLen].shape)\n",
        "          train = (X_train[:trainLen],y_train[:trainLen])\n",
        "          retriveLen = int(X_test.shape[0]*percent)\n",
        "          test = (X_test[:retriveLen],y_test[:retriveLen])\n",
        "          #print(tuple(train))\n",
        "          dataTrain.append(train)\n",
        "          dataTest.append(test)\n",
        "          #print(\"\\n\")\n",
        "          percent +=0.2\n",
        "      return dataTrain, dataTest\n",
        "  (X_train, y_train),(X_test, y_test) = load_dataset()\n",
        "  dataTrain, dataTest = divideDataset(X_train, y_train, X_test, y_test) # this contains the list of 5 different datasets\n",
        "  def normalizeInput(X_train,X_test):\n",
        "      X_train = X_train.astype('float32')\n",
        "      X_test = X_test.astype('float32')\n",
        "      mean = np.mean(X_train, axis=(0,1,2,3))\n",
        "      std = np.std(X_train,axis=(0,1,2,3))\n",
        "      X_train = (X_train-mean)/(std+1e-7)\n",
        "      X_test = (X_test-mean)/(std+1e-7)\n",
        "      \n",
        "      return X_train, X_test\n",
        "  ##### Include Little Data Augmentation \n",
        "  '''\n",
        "  batch_size = 64 # try several values\n",
        "\n",
        "  train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2, \n",
        "                                                                  width_shift_range=0.1, \n",
        "                                                                  height_shift_range = 0.1, \n",
        "                                                                  horizontal_flip=True)\n",
        "  \n",
        "  valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "  train_set_conv = train_DataGen.flow(X_train, y_train, batch_size=batch_size) # train_lab is categorical \n",
        "  valid_set_conv = valid_datagen.flow(X_test, y_test, batch_size=batch_size) # so as valid_lab\n",
        "  '''\n",
        "  X_train, X_test = normalizeInput(dataTrain[0][0], dataTest[0][0])\n",
        "  y_train = dataTrain[0][1]\n",
        "  y_test = dataTest[0][1]\n",
        "  # ResNet Implementation\n",
        "  # Code Link: https://github.com/Gurupradeep/CIFAR-10-Object-Recognition-in-Images/blob/master/Models/ResNet.ipynb\n",
        "  #Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
        "\n",
        "  #lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
        "  #csv_logger = CSVLogger('ResNet50_without_dropout_without_conv_without_pool0.csv')\n",
        "  early_stopper = EarlyStopping(min_delta=0.001, patience=30)\n",
        "  model_chekpoint = ModelCheckpoint(\"ResNet50_without_dropout_without_conv_without_pool.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)\n",
        "  #model Parameters\n",
        "  batch_size = 64\n",
        "  data_augmentation = False\n",
        "  epochs = 30\n",
        "  '''\n",
        "  if data_augmentation :\n",
        "      print(\"-------------Using Data augmentation------------\")\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "          height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False)  # randomly flip images\n",
        "      \n",
        "      datagen.fit(X_train)\n",
        "      model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                          epochs=epochs,verbose=1,validation_data=(X_test,y_test),callbacks = [lr_reducer,csv_logger])\n",
        "      \n",
        "  else :\n",
        "      print(\"-----Not Using Data augmentation---------------\")\n",
        "      model.fit(X_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(X_test, y_test),\n",
        "                shuffle=True,callbacks = [csv_logger])\n",
        "                '''\n",
        "  # RESNET50 WITH SKIP CONNECTION 2: Implemented by Lokesh\n",
        "  def createStageOne(x, filters,kernels, strides,paddings,counter):\n",
        "    '''\n",
        "    Argument\n",
        "    x - input\n",
        "    f - filter_size\n",
        "    k - kernel size\n",
        "    s - stride\n",
        "    p - padding\n",
        "    '''\n",
        "    f1, f2 = filters\n",
        "    k1, k2 = kernels\n",
        "    s1, s2 = strides\n",
        "    p1, p2 = paddings\n",
        "    block_name = 'stage_1'+counter\n",
        "    x_skip = x\n",
        "    x = Conv2D(f1, kernel_size=(k1,k1),strides=(s1,s1),padding=p1, name=block_name+'a')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(f2,kernel_size=(k2,k2),strides=(s2,s2),padding=p2,name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x_skip = Conv2D(f2,kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"Stage 1:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def createStageTwo(x,filters,kernels,strides,paddings,counter):\n",
        "    '''\n",
        "    Arguments\n",
        "    x - input\n",
        "    filters - filter size\n",
        "    kernels - kernel size\n",
        "    strides - stride size\n",
        "    paddings - padding size\n",
        "    '''\n",
        "    #print(\"stage 2\", x.shape)\n",
        "    f1, f2 = filters\n",
        "    k1, k2 = kernels\n",
        "    s1, s2 = strides\n",
        "    p1, p2 = paddings\n",
        "    block_name = 'stage_2'+counter\n",
        "    x_skip = x\n",
        "    x = Conv2D(f1,kernel_size=(k1,k1),strides=(s1,s1),padding=p1,name=block_name+'a')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(f2,kernel_size=(k2,k2),strides=(s2,s2),padding=p2,name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f2,kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f2,kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print('Stage 2:',x.shape)\n",
        "    return x\n",
        "  def createStageThree(x,filters,kernels,strides,paddings,counter):\n",
        "    '''\n",
        "    Arguments\n",
        "    x - input\n",
        "    filters - filter size\n",
        "    kernels - kernel size\n",
        "    strides - stride size\n",
        "    paddings - padding size\n",
        "    '''\n",
        "\n",
        "    f1, f2 = filters\n",
        "    k1, k2 = kernels\n",
        "    s1, s2 = strides\n",
        "    p1, p2 = paddings\n",
        "    block_name = 'stage_3'+counter\n",
        "    x_skip = x\n",
        "    x = Conv2D(f1,kernel_size=(k1,k1),strides=(s1,s1),padding=p1,name=block_name+'a')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(f2,kernel_size=(k2,k2),strides=(s2,s2),padding=p2,name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f2,kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f2,kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print('Stage 3:',x.shape)\n",
        "    return x\n",
        "  def createStageFour(x,filters,kernels,strides,paddings,counter):\n",
        "    '''\n",
        "    Arguments\n",
        "    x - input\n",
        "    filters - filter size\n",
        "    kernels - kernel size\n",
        "    strides - stride size\n",
        "    paddings - padding size\n",
        "    '''\n",
        "    f1, f2 = filters\n",
        "    k1, k2 = kernels\n",
        "    s1, s2 = strides\n",
        "    p1, p2 = paddings\n",
        "    block_name = 'stage_4'+counter\n",
        "    x_skip = x\n",
        "    x = Conv2D(f1,kernel_size=(k1,k1),strides=(s1,s1),padding=p1,name=block_name+'a')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(f2,kernel_size=(k2,k2),strides=(s2,s2),padding=p2,name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f2,kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f2,kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "  def resnet50():\n",
        "    inputs = Input(shape = (32,32,3), name = \"image_input\")\n",
        "    x = ZeroPadding2D((3,3))(inputs)\n",
        "    # Initial Convolutional block\n",
        "    \n",
        "    x = Conv2D(64, kernel_size=(7,7), strides = (2,2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3,3),strides=(2,2))(x)\n",
        "    x = createStageOne(x,[64,64],[1,3],[1,1],['valid','same'],'1')\n",
        "    x = createStageOne(x,[256,64],[1,1],[1,1],['valid','valid'],'2')\n",
        "    x = createStageOne(x,[64,256],[3,1],[1,1],['same','valid'],'3')\n",
        "    x = createStageOne(x,[64,64],[1,3],[1,1],['valid','same'],'4')\n",
        "    x = createStageTwo(x,[256,128],[1,1],[1,2],['valid','valid'],'5')\n",
        "    x = createStageTwo(x,[128,512],[3,1],[1,1],['same','valid'],'6')\n",
        "    x = createStageTwo(x,[128,128],[1,3],[1,1],['valid','same'],'7')\n",
        "    x = createStageTwo(x,[512,128],[1,1],[1,1],['valid','valid'],'8')\n",
        "    x = createStageTwo(x,[128,512],[3,1],[1,1],['same','valid'],'9')\n",
        "    x = createStageTwo(x,[128,128],[1,3],[1,1],['valid','same'],'10')\n",
        "    x = createStageThree(x,[512,256],[1,1],[1,2],['valid','valid'],'11')\n",
        "    x = createStageThree(x,[256,1024],[3,1],[1,1],['same','valid'],'12')\n",
        "    x = createStageThree(x,[256,256],[1,3],[1,1],['valid','same'],'13')\n",
        "    x = createStageThree(x,[1024,256],[1,1],[1,1],['valid','valid'],'14')\n",
        "    x = createStageThree(x,[256,1024],[3,1],[1,1],['same','valid'],'15')\n",
        "    x = createStageThree(x,[256,256],[1,3],[1,1],['valid','same'],'16')\n",
        "    x = createStageThree(x,[1024,256],[1,1],[1,1],['valid','valid'],'17')\n",
        "    x = createStageThree(x,[256,1024],[3,1],[1,1],['same','valid'],'18')\n",
        "    x = createStageThree(x,[256,256],[1,3],[1,1],['valid','same'],'19')\n",
        "    x = createStageFour(x,[1024,512],[1,1],[1,2],['valid','valid'],'20')\n",
        "    x = createStageFour(x,[512,2048],[3,1],[1,1],['same','valid'],'21')\n",
        "    x = createStageFour(x,[512,512],[1,3],[1,1],['valid','same'],'22')\n",
        "    x = createStageFour(x,[2048,512],[1,1],[1,1],['valid','valid'],'23')\n",
        "    x = createStageFour(x,[512,2048],[3,1],[1,1],['same','valid'],'24')\n",
        "    x = AveragePooling2D((2,2),name='avg_pool',padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(10,activation='softmax')(x)\n",
        "    model = Model(inputs=inputs,outputs=x, name='LResNet50')\n",
        "\n",
        "    return model\n",
        "\n",
        "  model = resnet50()\n",
        "  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  #model.summary()\n",
        "  X_train, X_test = normalizeInput(dataTrain[i][0], dataTest[i][0])\n",
        "  y_train = dataTrain[i][1]\n",
        "  y_test = dataTest[i][1]\n",
        "  print(\"Len: \", len(X_train))\n",
        "  earlyStop = EarlyStopping(monitor='loss',patience=5,mode='auto')\n",
        "  csvLogger = CSVLogger('/content/drive/MyDrive/PhD Studies/fall21/ADVML/results/skip2/'+str(i)+'.csv')\n",
        "  history = model.fit(X_train,y_train, epochs=300,batch_size=1024,validation_split=0.3,verbose=1, callbacks=[csvLogger,earlyStop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len:  10000\n",
            "Epoch 1/300\n",
            "7/7 [==============================] - 16s 850ms/step - loss: 3.2429 - accuracy: 0.1106 - val_loss: 2.3045 - val_accuracy: 0.0933\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 2.4724 - accuracy: 0.1453 - val_loss: 2.3055 - val_accuracy: 0.0933\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 2.2261 - accuracy: 0.1766 - val_loss: 2.3106 - val_accuracy: 0.0933\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 2.1304 - accuracy: 0.2046 - val_loss: 2.3211 - val_accuracy: 0.0933\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 2.0447 - accuracy: 0.2249 - val_loss: 2.3449 - val_accuracy: 0.0933\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 1.9519 - accuracy: 0.2594 - val_loss: 2.3745 - val_accuracy: 0.0933\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 1.8425 - accuracy: 0.2896 - val_loss: 2.3915 - val_accuracy: 0.0997\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 1.6966 - accuracy: 0.3314 - val_loss: 2.4677 - val_accuracy: 0.0907\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 1.6406 - accuracy: 0.3507 - val_loss: 2.6440 - val_accuracy: 0.1017\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 1.4862 - accuracy: 0.3967 - val_loss: 2.6663 - val_accuracy: 0.0913\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 1.3971 - accuracy: 0.4313 - val_loss: 2.7185 - val_accuracy: 0.1067\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 1.2924 - accuracy: 0.4847 - val_loss: 2.8106 - val_accuracy: 0.1067\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 2s 245ms/step - loss: 1.2144 - accuracy: 0.5190 - val_loss: 2.8541 - val_accuracy: 0.1067\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 1.1479 - accuracy: 0.5526 - val_loss: 3.0235 - val_accuracy: 0.1097\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 1.0930 - accuracy: 0.5866 - val_loss: 3.2173 - val_accuracy: 0.0997\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 1.0151 - accuracy: 0.6140 - val_loss: 3.3084 - val_accuracy: 0.1057\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.8415 - accuracy: 0.6830 - val_loss: 3.7037 - val_accuracy: 0.1163\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.7542 - accuracy: 0.7306 - val_loss: 3.8713 - val_accuracy: 0.1047\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.7350 - accuracy: 0.7307 - val_loss: 3.9139 - val_accuracy: 0.1120\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.7211 - accuracy: 0.7377 - val_loss: 4.4543 - val_accuracy: 0.1087\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.6238 - accuracy: 0.7739 - val_loss: 4.8739 - val_accuracy: 0.1143\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.5470 - accuracy: 0.8036 - val_loss: 5.1386 - val_accuracy: 0.1127\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.5915 - accuracy: 0.7866 - val_loss: 4.7288 - val_accuracy: 0.1103\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.5223 - accuracy: 0.8154 - val_loss: 4.4364 - val_accuracy: 0.1260\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.4432 - accuracy: 0.8487 - val_loss: 5.1009 - val_accuracy: 0.1217\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.4411 - accuracy: 0.8486 - val_loss: 5.4161 - val_accuracy: 0.1120\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 2s 245ms/step - loss: 0.4152 - accuracy: 0.8533 - val_loss: 5.3897 - val_accuracy: 0.1157\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.3837 - accuracy: 0.8633 - val_loss: 6.5054 - val_accuracy: 0.1067\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.3136 - accuracy: 0.8897 - val_loss: 6.6950 - val_accuracy: 0.1060\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.2714 - accuracy: 0.9034 - val_loss: 6.2638 - val_accuracy: 0.1210\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.2861 - accuracy: 0.8989 - val_loss: 6.7761 - val_accuracy: 0.1143\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.3100 - accuracy: 0.8899 - val_loss: 5.7919 - val_accuracy: 0.1430\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.2807 - accuracy: 0.9020 - val_loss: 5.6165 - val_accuracy: 0.1480\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 5.9040 - val_accuracy: 0.1637\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.2315 - accuracy: 0.9194 - val_loss: 5.7336 - val_accuracy: 0.1810\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.2309 - accuracy: 0.9193 - val_loss: 5.4208 - val_accuracy: 0.1857\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.2388 - accuracy: 0.9156 - val_loss: 5.0546 - val_accuracy: 0.2090\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.1985 - accuracy: 0.9277 - val_loss: 5.2170 - val_accuracy: 0.2220\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.1644 - accuracy: 0.9426 - val_loss: 5.4671 - val_accuracy: 0.2023\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.2010 - accuracy: 0.9257 - val_loss: 5.4163 - val_accuracy: 0.2230\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.2102 - accuracy: 0.9267 - val_loss: 5.0716 - val_accuracy: 0.2443\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 2s 245ms/step - loss: 0.2094 - accuracy: 0.9293 - val_loss: 4.8329 - val_accuracy: 0.2660\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.1597 - accuracy: 0.9461 - val_loss: 5.4557 - val_accuracy: 0.2360\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.1467 - accuracy: 0.9501 - val_loss: 5.0484 - val_accuracy: 0.2657\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.1560 - accuracy: 0.9476 - val_loss: 4.7995 - val_accuracy: 0.2813\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.1757 - accuracy: 0.9430 - val_loss: 4.8486 - val_accuracy: 0.2693\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.1994 - accuracy: 0.9316 - val_loss: 4.7354 - val_accuracy: 0.2767\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.1908 - accuracy: 0.9381 - val_loss: 4.9375 - val_accuracy: 0.2727\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.1522 - accuracy: 0.9486 - val_loss: 4.9203 - val_accuracy: 0.2743\n",
            "Len:  20000\n",
            "Epoch 1/300\n",
            "14/14 [==============================] - 16s 535ms/step - loss: 2.7572 - accuracy: 0.1274 - val_loss: 2.3035 - val_accuracy: 0.0992\n",
            "Epoch 2/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 2.1870 - accuracy: 0.1811 - val_loss: 2.3074 - val_accuracy: 0.0992\n",
            "Epoch 3/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 2.0609 - accuracy: 0.2219 - val_loss: 2.3164 - val_accuracy: 0.0992\n",
            "Epoch 4/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 1.9321 - accuracy: 0.2654 - val_loss: 2.3320 - val_accuracy: 0.0992\n",
            "Epoch 5/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 1.7928 - accuracy: 0.3152 - val_loss: 2.3817 - val_accuracy: 0.0993\n",
            "Epoch 6/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 1.6456 - accuracy: 0.3767 - val_loss: 2.4453 - val_accuracy: 0.1022\n",
            "Epoch 7/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 1.4784 - accuracy: 0.4320 - val_loss: 2.4610 - val_accuracy: 0.1065\n",
            "Epoch 8/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 1.3834 - accuracy: 0.4818 - val_loss: 2.5320 - val_accuracy: 0.0997\n",
            "Epoch 9/300\n",
            "14/14 [==============================] - 3s 244ms/step - loss: 1.2719 - accuracy: 0.5217 - val_loss: 2.7559 - val_accuracy: 0.1195\n",
            "Epoch 10/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 1.1943 - accuracy: 0.5550 - val_loss: 2.7214 - val_accuracy: 0.1160\n",
            "Epoch 11/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 1.0923 - accuracy: 0.5954 - val_loss: 3.0661 - val_accuracy: 0.1328\n",
            "Epoch 12/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 1.0300 - accuracy: 0.6232 - val_loss: 4.2909 - val_accuracy: 0.1133\n",
            "Epoch 13/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.9417 - accuracy: 0.6616 - val_loss: 4.4834 - val_accuracy: 0.1117\n",
            "Epoch 14/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.8455 - accuracy: 0.7000 - val_loss: 5.1556 - val_accuracy: 0.1145\n",
            "Epoch 15/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.8012 - accuracy: 0.7135 - val_loss: 4.3779 - val_accuracy: 0.1458\n",
            "Epoch 16/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.6977 - accuracy: 0.7510 - val_loss: 4.9997 - val_accuracy: 0.1420\n",
            "Epoch 17/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.6671 - accuracy: 0.7637 - val_loss: 5.0943 - val_accuracy: 0.1748\n",
            "Epoch 18/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.6451 - accuracy: 0.7836 - val_loss: 5.0163 - val_accuracy: 0.1677\n",
            "Epoch 19/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.6356 - accuracy: 0.7838 - val_loss: 4.1448 - val_accuracy: 0.2202\n",
            "Epoch 20/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.5253 - accuracy: 0.8230 - val_loss: 4.0920 - val_accuracy: 0.2638\n",
            "Epoch 21/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.5051 - accuracy: 0.8293 - val_loss: 4.0598 - val_accuracy: 0.2923\n",
            "Epoch 22/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.4682 - accuracy: 0.8433 - val_loss: 4.6465 - val_accuracy: 0.2725\n",
            "Epoch 23/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.4127 - accuracy: 0.8596 - val_loss: 5.4318 - val_accuracy: 0.2710\n",
            "Epoch 24/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.4191 - accuracy: 0.8558 - val_loss: 3.9948 - val_accuracy: 0.3103\n",
            "Epoch 25/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.3953 - accuracy: 0.8651 - val_loss: 4.0749 - val_accuracy: 0.3128\n",
            "Epoch 26/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.2962 - accuracy: 0.8998 - val_loss: 4.0918 - val_accuracy: 0.3362\n",
            "Epoch 27/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.3161 - accuracy: 0.8977 - val_loss: 4.4302 - val_accuracy: 0.3208\n",
            "Epoch 28/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.2697 - accuracy: 0.9086 - val_loss: 4.1281 - val_accuracy: 0.3490\n",
            "Epoch 29/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.2757 - accuracy: 0.9068 - val_loss: 3.9586 - val_accuracy: 0.3433\n",
            "Epoch 30/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.3117 - accuracy: 0.8934 - val_loss: 4.3760 - val_accuracy: 0.3348\n",
            "Epoch 31/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.2308 - accuracy: 0.9197 - val_loss: 4.0853 - val_accuracy: 0.3530\n",
            "Epoch 32/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1954 - accuracy: 0.9319 - val_loss: 4.2497 - val_accuracy: 0.3497\n",
            "Epoch 33/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.2174 - accuracy: 0.9270 - val_loss: 4.2290 - val_accuracy: 0.3502\n",
            "Epoch 34/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.2076 - accuracy: 0.9288 - val_loss: 4.0667 - val_accuracy: 0.3595\n",
            "Epoch 35/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1613 - accuracy: 0.9456 - val_loss: 4.4574 - val_accuracy: 0.3505\n",
            "Epoch 36/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1677 - accuracy: 0.9444 - val_loss: 4.1728 - val_accuracy: 0.3628\n",
            "Epoch 37/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1831 - accuracy: 0.9412 - val_loss: 4.1339 - val_accuracy: 0.3513\n",
            "Epoch 38/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1752 - accuracy: 0.9403 - val_loss: 4.2916 - val_accuracy: 0.3567\n",
            "Epoch 39/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1589 - accuracy: 0.9473 - val_loss: 4.3179 - val_accuracy: 0.3600\n",
            "Epoch 40/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1518 - accuracy: 0.9492 - val_loss: 4.1213 - val_accuracy: 0.3622\n",
            "Epoch 41/300\n",
            "14/14 [==============================] - 3s 241ms/step - loss: 0.1458 - accuracy: 0.9511 - val_loss: 4.2041 - val_accuracy: 0.3707\n",
            "Epoch 42/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1502 - accuracy: 0.9510 - val_loss: 4.4578 - val_accuracy: 0.3587\n",
            "Epoch 43/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1451 - accuracy: 0.9523 - val_loss: 4.1517 - val_accuracy: 0.3570\n",
            "Epoch 44/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1375 - accuracy: 0.9536 - val_loss: 4.2300 - val_accuracy: 0.3572\n",
            "Epoch 45/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1031 - accuracy: 0.9660 - val_loss: 4.3041 - val_accuracy: 0.3702\n",
            "Epoch 46/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.0987 - accuracy: 0.9649 - val_loss: 4.2776 - val_accuracy: 0.3793\n",
            "Epoch 47/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1180 - accuracy: 0.9601 - val_loss: 4.2130 - val_accuracy: 0.3750\n",
            "Epoch 48/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1460 - accuracy: 0.9508 - val_loss: 4.0867 - val_accuracy: 0.3730\n",
            "Epoch 49/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1269 - accuracy: 0.9596 - val_loss: 4.0126 - val_accuracy: 0.3792\n",
            "Epoch 50/300\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.1143 - accuracy: 0.9609 - val_loss: 4.3191 - val_accuracy: 0.3610\n",
            "Epoch 51/300\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.1185 - accuracy: 0.9601 - val_loss: 4.0447 - val_accuracy: 0.3683\n",
            "Len:  30000\n",
            "Epoch 1/300\n",
            "21/21 [==============================] - 17s 413ms/step - loss: 2.5560 - accuracy: 0.1369 - val_loss: 2.3076 - val_accuracy: 0.0957\n",
            "Epoch 2/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 2.0965 - accuracy: 0.2154 - val_loss: 2.3343 - val_accuracy: 0.0976\n",
            "Epoch 3/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 1.9286 - accuracy: 0.2774 - val_loss: 2.4000 - val_accuracy: 0.0976\n",
            "Epoch 4/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 1.7802 - accuracy: 0.3442 - val_loss: 2.4672 - val_accuracy: 0.1026\n",
            "Epoch 5/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 1.6184 - accuracy: 0.4022 - val_loss: 2.6108 - val_accuracy: 0.1026\n",
            "Epoch 6/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 1.4646 - accuracy: 0.4575 - val_loss: 2.9342 - val_accuracy: 0.0994\n",
            "Epoch 7/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 1.3238 - accuracy: 0.5154 - val_loss: 4.0982 - val_accuracy: 0.0988\n",
            "Epoch 8/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 1.2162 - accuracy: 0.5563 - val_loss: 3.3790 - val_accuracy: 0.1104\n",
            "Epoch 9/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 1.1312 - accuracy: 0.5911 - val_loss: 4.5222 - val_accuracy: 0.0988\n",
            "Epoch 10/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 1.0235 - accuracy: 0.6306 - val_loss: 4.2583 - val_accuracy: 0.1241\n",
            "Epoch 11/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.9545 - accuracy: 0.6530 - val_loss: 4.1737 - val_accuracy: 0.1401\n",
            "Epoch 12/300\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.9040 - accuracy: 0.6740 - val_loss: 4.2221 - val_accuracy: 0.1676\n",
            "Epoch 13/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.8481 - accuracy: 0.6978 - val_loss: 4.4868 - val_accuracy: 0.1678\n",
            "Epoch 14/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.7459 - accuracy: 0.7374 - val_loss: 3.7572 - val_accuracy: 0.2211\n",
            "Epoch 15/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.6887 - accuracy: 0.7578 - val_loss: 3.8586 - val_accuracy: 0.2347\n",
            "Epoch 16/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.6761 - accuracy: 0.7624 - val_loss: 3.6460 - val_accuracy: 0.2903\n",
            "Epoch 17/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.6441 - accuracy: 0.7768 - val_loss: 4.0813 - val_accuracy: 0.2854\n",
            "Epoch 18/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.5495 - accuracy: 0.8078 - val_loss: 3.4426 - val_accuracy: 0.3482\n",
            "Epoch 19/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.5154 - accuracy: 0.8235 - val_loss: 3.3185 - val_accuracy: 0.3769\n",
            "Epoch 20/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.4816 - accuracy: 0.8322 - val_loss: 3.6488 - val_accuracy: 0.3567\n",
            "Epoch 21/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.4347 - accuracy: 0.8495 - val_loss: 3.5156 - val_accuracy: 0.3610\n",
            "Epoch 22/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.4155 - accuracy: 0.8582 - val_loss: 3.8189 - val_accuracy: 0.3563\n",
            "Epoch 23/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.3650 - accuracy: 0.8735 - val_loss: 3.5425 - val_accuracy: 0.3614\n",
            "Epoch 24/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.3473 - accuracy: 0.8810 - val_loss: 3.5437 - val_accuracy: 0.3749\n",
            "Epoch 25/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.3441 - accuracy: 0.8818 - val_loss: 3.9938 - val_accuracy: 0.3464\n",
            "Epoch 26/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.2980 - accuracy: 0.8979 - val_loss: 3.5210 - val_accuracy: 0.3871\n",
            "Epoch 27/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.2638 - accuracy: 0.9089 - val_loss: 3.5001 - val_accuracy: 0.3882\n",
            "Epoch 28/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.2612 - accuracy: 0.9105 - val_loss: 3.8889 - val_accuracy: 0.3712\n",
            "Epoch 29/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.3110 - accuracy: 0.8925 - val_loss: 3.4188 - val_accuracy: 0.3974\n",
            "Epoch 30/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.2282 - accuracy: 0.9237 - val_loss: 4.0336 - val_accuracy: 0.3929\n",
            "Epoch 31/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.2150 - accuracy: 0.9262 - val_loss: 3.5607 - val_accuracy: 0.4037\n",
            "Epoch 32/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.2133 - accuracy: 0.9284 - val_loss: 3.7062 - val_accuracy: 0.3979\n",
            "Epoch 33/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.2107 - accuracy: 0.9266 - val_loss: 3.5666 - val_accuracy: 0.4150\n",
            "Epoch 34/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1944 - accuracy: 0.9333 - val_loss: 3.6560 - val_accuracy: 0.3973\n",
            "Epoch 35/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1944 - accuracy: 0.9332 - val_loss: 3.9156 - val_accuracy: 0.3964\n",
            "Epoch 36/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1854 - accuracy: 0.9366 - val_loss: 3.5250 - val_accuracy: 0.4092\n",
            "Epoch 37/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1732 - accuracy: 0.9422 - val_loss: 3.5428 - val_accuracy: 0.3897\n",
            "Epoch 38/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1865 - accuracy: 0.9360 - val_loss: 3.5283 - val_accuracy: 0.4007\n",
            "Epoch 39/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1878 - accuracy: 0.9372 - val_loss: 3.8423 - val_accuracy: 0.3876\n",
            "Epoch 40/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1686 - accuracy: 0.9435 - val_loss: 3.9787 - val_accuracy: 0.3930\n",
            "Epoch 41/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1619 - accuracy: 0.9452 - val_loss: 3.6769 - val_accuracy: 0.4020\n",
            "Epoch 42/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1542 - accuracy: 0.9480 - val_loss: 3.8545 - val_accuracy: 0.4063\n",
            "Epoch 43/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1218 - accuracy: 0.9595 - val_loss: 3.7834 - val_accuracy: 0.3970\n",
            "Epoch 44/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1414 - accuracy: 0.9502 - val_loss: 3.6000 - val_accuracy: 0.4062\n",
            "Epoch 45/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1365 - accuracy: 0.9526 - val_loss: 3.7447 - val_accuracy: 0.4264\n",
            "Epoch 46/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1405 - accuracy: 0.9536 - val_loss: 4.0652 - val_accuracy: 0.4153\n",
            "Epoch 47/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1075 - accuracy: 0.9637 - val_loss: 3.6070 - val_accuracy: 0.4214\n",
            "Epoch 48/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.0981 - accuracy: 0.9671 - val_loss: 3.8421 - val_accuracy: 0.4174\n",
            "Epoch 49/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1074 - accuracy: 0.9625 - val_loss: 3.7782 - val_accuracy: 0.4109\n",
            "Epoch 50/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1276 - accuracy: 0.9570 - val_loss: 3.6380 - val_accuracy: 0.4149\n",
            "Epoch 51/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1272 - accuracy: 0.9568 - val_loss: 3.7863 - val_accuracy: 0.4269\n",
            "Epoch 52/300\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.1172 - accuracy: 0.9598 - val_loss: 3.8185 - val_accuracy: 0.4136\n",
            "Epoch 53/300\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.1101 - accuracy: 0.9625 - val_loss: 3.5642 - val_accuracy: 0.4261\n",
            "Len:  40000\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 19s 367ms/step - loss: 2.4934 - accuracy: 0.1477 - val_loss: 2.3052 - val_accuracy: 0.1004\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 2.0481 - accuracy: 0.2280 - val_loss: 2.3243 - val_accuracy: 0.0963\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 1.8983 - accuracy: 0.2806 - val_loss: 2.3270 - val_accuracy: 0.1044\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 1.7549 - accuracy: 0.3336 - val_loss: 2.4867 - val_accuracy: 0.1063\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 1.6059 - accuracy: 0.3932 - val_loss: 2.6187 - val_accuracy: 0.1070\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 1.4655 - accuracy: 0.4533 - val_loss: 2.9497 - val_accuracy: 0.1192\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 1.3629 - accuracy: 0.4948 - val_loss: 2.8842 - val_accuracy: 0.1259\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 7s 239ms/step - loss: 1.2656 - accuracy: 0.5275 - val_loss: 2.6957 - val_accuracy: 0.1653\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 1.1459 - accuracy: 0.5740 - val_loss: 2.8518 - val_accuracy: 0.1953\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 1.1090 - accuracy: 0.5943 - val_loss: 3.1852 - val_accuracy: 0.2261\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.9945 - accuracy: 0.6313 - val_loss: 2.7696 - val_accuracy: 0.2682\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.9083 - accuracy: 0.6681 - val_loss: 2.6555 - val_accuracy: 0.3022\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.8700 - accuracy: 0.6833 - val_loss: 2.8815 - val_accuracy: 0.3031\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.7868 - accuracy: 0.7149 - val_loss: 3.0822 - val_accuracy: 0.3117\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.7642 - accuracy: 0.7234 - val_loss: 3.1042 - val_accuracy: 0.3301\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.6810 - accuracy: 0.7546 - val_loss: 2.8288 - val_accuracy: 0.3623\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.6438 - accuracy: 0.7696 - val_loss: 3.0863 - val_accuracy: 0.3518\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.5795 - accuracy: 0.7940 - val_loss: 2.9995 - val_accuracy: 0.3773\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.5324 - accuracy: 0.8114 - val_loss: 3.0866 - val_accuracy: 0.3687\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.5107 - accuracy: 0.8185 - val_loss: 3.1203 - val_accuracy: 0.3916\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.4975 - accuracy: 0.8226 - val_loss: 3.1823 - val_accuracy: 0.3880\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.4590 - accuracy: 0.8409 - val_loss: 3.2151 - val_accuracy: 0.3861\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 7s 239ms/step - loss: 0.4177 - accuracy: 0.8539 - val_loss: 3.0782 - val_accuracy: 0.4005\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.3893 - accuracy: 0.8639 - val_loss: 3.1465 - val_accuracy: 0.3778\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.3803 - accuracy: 0.8666 - val_loss: 3.2497 - val_accuracy: 0.4051\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.3338 - accuracy: 0.8825 - val_loss: 3.1760 - val_accuracy: 0.4103\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.3203 - accuracy: 0.8875 - val_loss: 3.2873 - val_accuracy: 0.4009\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.3267 - accuracy: 0.8856 - val_loss: 3.3770 - val_accuracy: 0.4166\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.3032 - accuracy: 0.8943 - val_loss: 3.2112 - val_accuracy: 0.4133\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2658 - accuracy: 0.9091 - val_loss: 3.3988 - val_accuracy: 0.4034\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2683 - accuracy: 0.9053 - val_loss: 3.3534 - val_accuracy: 0.4142\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2457 - accuracy: 0.9143 - val_loss: 3.1833 - val_accuracy: 0.4256\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2231 - accuracy: 0.9243 - val_loss: 3.3305 - val_accuracy: 0.4272\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2314 - accuracy: 0.9189 - val_loss: 3.3334 - val_accuracy: 0.4231\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.2262 - accuracy: 0.9236 - val_loss: 3.4012 - val_accuracy: 0.4284\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.2161 - accuracy: 0.9270 - val_loss: 3.5398 - val_accuracy: 0.4047\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2079 - accuracy: 0.9293 - val_loss: 3.3012 - val_accuracy: 0.4373\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.2118 - accuracy: 0.9280 - val_loss: 3.2687 - val_accuracy: 0.4233\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.1913 - accuracy: 0.9359 - val_loss: 3.3980 - val_accuracy: 0.4293\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1875 - accuracy: 0.9347 - val_loss: 3.2468 - val_accuracy: 0.4321\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.1838 - accuracy: 0.9375 - val_loss: 3.2270 - val_accuracy: 0.4402\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 7s 239ms/step - loss: 0.1634 - accuracy: 0.9440 - val_loss: 3.2982 - val_accuracy: 0.4411\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1722 - accuracy: 0.9415 - val_loss: 3.3138 - val_accuracy: 0.4432\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1481 - accuracy: 0.9491 - val_loss: 3.5448 - val_accuracy: 0.4336\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1670 - accuracy: 0.9418 - val_loss: 3.7287 - val_accuracy: 0.4124\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1704 - accuracy: 0.9416 - val_loss: 3.2107 - val_accuracy: 0.4430\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.1597 - accuracy: 0.9459 - val_loss: 3.2781 - val_accuracy: 0.4460\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1430 - accuracy: 0.9506 - val_loss: 3.3849 - val_accuracy: 0.4439\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1332 - accuracy: 0.9548 - val_loss: 3.2754 - val_accuracy: 0.4549\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1543 - accuracy: 0.9475 - val_loss: 3.1906 - val_accuracy: 0.4530\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 7s 241ms/step - loss: 0.1561 - accuracy: 0.9470 - val_loss: 3.3957 - val_accuracy: 0.4325\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1799 - accuracy: 0.9398 - val_loss: 3.0468 - val_accuracy: 0.4506\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1391 - accuracy: 0.9525 - val_loss: 3.1863 - val_accuracy: 0.4556\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 7s 240ms/step - loss: 0.1562 - accuracy: 0.9461 - val_loss: 3.2238 - val_accuracy: 0.4468\n",
            "Len:  50000\n",
            "Epoch 1/300\n",
            "35/35 [==============================] - 20s 325ms/step - loss: 2.4436 - accuracy: 0.1562 - val_loss: 2.3034 - val_accuracy: 0.0979\n",
            "Epoch 2/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.9828 - accuracy: 0.2513 - val_loss: 2.3286 - val_accuracy: 0.1014\n",
            "Epoch 3/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.8120 - accuracy: 0.3153 - val_loss: 2.4043 - val_accuracy: 0.1017\n",
            "Epoch 4/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.6900 - accuracy: 0.3722 - val_loss: 2.4640 - val_accuracy: 0.1212\n",
            "Epoch 5/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.5716 - accuracy: 0.4190 - val_loss: 2.5850 - val_accuracy: 0.1149\n",
            "Epoch 6/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.4727 - accuracy: 0.4643 - val_loss: 2.1581 - val_accuracy: 0.2213\n",
            "Epoch 7/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.3736 - accuracy: 0.4980 - val_loss: 2.2356 - val_accuracy: 0.2337\n",
            "Epoch 8/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.2585 - accuracy: 0.5430 - val_loss: 2.2082 - val_accuracy: 0.3080\n",
            "Epoch 9/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.1895 - accuracy: 0.5705 - val_loss: 2.1231 - val_accuracy: 0.3451\n",
            "Epoch 10/300\n",
            "35/35 [==============================] - 8s 242ms/step - loss: 1.1307 - accuracy: 0.5951 - val_loss: 2.1202 - val_accuracy: 0.4001\n",
            "Epoch 11/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.0407 - accuracy: 0.6282 - val_loss: 2.3281 - val_accuracy: 0.4077\n",
            "Epoch 12/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 0.9743 - accuracy: 0.6550 - val_loss: 2.4441 - val_accuracy: 0.3887\n",
            "Epoch 13/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 0.9628 - accuracy: 0.6612 - val_loss: 2.6135 - val_accuracy: 0.4104\n",
            "Epoch 14/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 0.8790 - accuracy: 0.6881 - val_loss: 2.4915 - val_accuracy: 0.4075\n",
            "Epoch 15/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 0.8320 - accuracy: 0.7106 - val_loss: 3.3588 - val_accuracy: 0.3220\n",
            "Epoch 16/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.7021 - accuracy: 0.4031 - val_loss: 675.5653 - val_accuracy: 0.1238\n",
            "Epoch 17/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.5004 - accuracy: 0.4583 - val_loss: 109.7668 - val_accuracy: 0.1894\n",
            "Epoch 18/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.2987 - accuracy: 0.5334 - val_loss: 2.2959 - val_accuracy: 0.3861\n",
            "Epoch 19/300\n",
            "35/35 [==============================] - 8s 241ms/step - loss: 1.1197 - accuracy: 0.6009 - val_loss: 1.8021 - val_accuracy: 0.4169\n",
            "Epoch 20/300\n",
            "35/35 [==============================] - 8s 240ms/step - loss: 0.9638 - accuracy: 0.6579 - val_loss: 1.8483 - val_accuracy: 0.4381\n"
          ]
        }
      ]
    }
  ]
}