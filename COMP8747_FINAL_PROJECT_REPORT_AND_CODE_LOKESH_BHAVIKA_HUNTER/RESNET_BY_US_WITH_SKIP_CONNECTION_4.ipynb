{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "RESNET_BY_US_WITH_SKIP_CONNECTION_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-T7ILCuImn"
      },
      "source": [
        "# Useful Links\n",
        "# 1. https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "# 2. https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/\n",
        "# 3. https://towardsdatascience.com/resnets-for-cifar-10-e63e900524e0 (Understanding the resnet architecture for cifar10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbYz2fluImp"
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8pcvbhEsEtC",
        "outputId": "f31afcc0-854d-42e4-cfa2-117e9b9b5df5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "PATH = '/content/drive/MyDrive/PhD Studies/fall21/ADVML/results/skip4/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6OuColuImq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae3bf38-0b3e-4fd4-9a46-0c5e2dffb064"
      },
      "source": [
        "# Load necessary libraries\n",
        "for i in range(5):\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  #import cv2\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import backend as K\n",
        "  from tensorflow.keras.optimizers import SGD, Adam\n",
        "  #from google.colab.patches import cv2_imshow\n",
        "  from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "  from tensorflow.keras.models import Sequential, Model,load_model\n",
        "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "  from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D,Dropout\n",
        "  from tensorflow.keras.preprocessing import image\n",
        "  from tensorflow.keras.initializers import glorot_uniform\n",
        "  from matplotlib import pyplot as plt\n",
        "  from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "\n",
        "\n",
        "  def load_dataset(dName=\"CIFAR10\"):\n",
        "      dataset = None\n",
        "      num_classes = None\n",
        "      if dName == \"CIFAR10\":\n",
        "          num_classes = 10\n",
        "          dataset = tf.keras.datasets.cifar10.load_data()\n",
        "      if dName == \"CIFAR100\":\n",
        "          num_classes = 100\n",
        "          dataset = tf.keras.datasets.cifar100.load_data()\n",
        "      (X_train, y_train), (X_test, y_test) = dataset\n",
        "      # Convert target value to categorical values\n",
        "      # One-hot-encoded target values\n",
        "      y_train = to_categorical(y_train,num_classes)\n",
        "      y_test = to_categorical(y_test, num_classes)\n",
        "      \n",
        "      return (X_train, y_train),(X_test, y_test)\n",
        "  def divideDataset(X_train, y_train, X_test,y_test):\n",
        "      dataLength = X_train.shape[0]\n",
        "      trainLen=0\n",
        "      dataTrain = []\n",
        "      dataTest = []\n",
        "      percent = 0.2\n",
        "      while(trainLen<dataLength):\n",
        "          trainLen = int(X_train.shape[0]*percent)\n",
        "          #print(X_train[:trainLen].shape)\n",
        "          train = (X_train[:trainLen],y_train[:trainLen])\n",
        "          retriveLen = int(X_test.shape[0]*percent)\n",
        "          test = (X_test[:retriveLen],y_test[:retriveLen])\n",
        "          #print(tuple(train))\n",
        "          dataTrain.append(train)\n",
        "          dataTest.append(test)\n",
        "          #print(\"\\n\")\n",
        "          percent +=0.2\n",
        "      return dataTrain, dataTest\n",
        "  (X_train, y_train),(X_test, y_test) = load_dataset()\n",
        "  dataTrain, dataTest = divideDataset(X_train, y_train, X_test, y_test) # this contains the list of 5 different datasets\n",
        "  def normalizeInput(X_train,X_test):\n",
        "      X_train = X_train.astype('float32')\n",
        "      X_test = X_test.astype('float32')\n",
        "      mean = np.mean(X_train, axis=(0,1,2,3))\n",
        "      std = np.std(X_train,axis=(0,1,2,3))\n",
        "      X_train = (X_train-mean)/(std+1e-7)\n",
        "      X_test = (X_test-mean)/(std+1e-7)\n",
        "      \n",
        "      return X_train, X_test\n",
        "  X_train, X_test = normalizeInput(dataTrain[0][0], dataTest[0][0])\n",
        "  y_train = dataTrain[0][1]\n",
        "  y_test = dataTest[0][1]\n",
        "  # RESNET50 WITH SKIP CONNECTION 4: Implemented by Lokesh\n",
        "  def createStageOne(x, f,k, s,p,counter):\n",
        "    '''\n",
        "    Argument\n",
        "    x - input\n",
        "    f - filter_size\n",
        "    k - kernel size\n",
        "    s - stride\n",
        "    p - padding\n",
        "    '''\n",
        "    block_name = 'stage_1'+counter\n",
        "    x_skip = x\n",
        "    layers = len(f)\n",
        "    for i in range(layers):\n",
        "      x = Conv2D(f[i],kernel_size=(k[i],k[i]),strides=(s[i],s[i]),padding=p[i])(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "    x = Conv2D(f[layers-1],kernel_size=(k[layers-1],k[layers-1]),strides=(s[layers-1],s[layers-1]),padding=p[layers-1],name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    print(x.shape)\n",
        "\n",
        "    x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"Stage 1:\", (x_skip.shape,x.shape))\n",
        "\n",
        "    return x\n",
        "\n",
        "  def createStageTwo_(x, f,k, s,p,counter):\n",
        "    '''\n",
        "    Argument\n",
        "    x - input\n",
        "    f - filter_size\n",
        "    k - kernel size\n",
        "    s - stride\n",
        "    p - padding\n",
        "    '''\n",
        "    block_name = 'stage_2'+counter\n",
        "    x_skip = x\n",
        "    #print(\"Recevied Input at Stage 2: \", x.shape)\n",
        "    layers = len(f)\n",
        "    for i in range(layers):\n",
        "      x = Conv2D(f[i],kernel_size=(k[i],k[i]),strides=(s[i],s[i]),padding=p[i])(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "    x = Conv2D(f[layers-1],kernel_size=(k[layers-1],k[layers-1]),strides=(s[layers-1],s[layers-1]),padding=p[layers-1],name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    print(x.shape)\n",
        "\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "\n",
        "    x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"Stage 2:\", (x_skip.shape,x.shape))\n",
        "\n",
        "    return x\n",
        "\n",
        "  def createStageThree_(x, f,k, s,p,counter):\n",
        "    '''\n",
        "    Argument\n",
        "    x - input\n",
        "    f - filter_size\n",
        "    k - kernel size\n",
        "    s - stride\n",
        "    p - padding\n",
        "    '''\n",
        "    block_name = 'stage_3'+counter\n",
        "    x_skip = x\n",
        "    #print(\"Recevied Input at Stage 3: \", x.shape)\n",
        "    layers = len(f)\n",
        "    for i in range(layers):\n",
        "      x = Conv2D(f[i],kernel_size=(k[i],k[i]),strides=(s[i],s[i]),padding=p[i])(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "    x = Conv2D(f[layers-1],kernel_size=(k[layers-1],k[layers-1]),strides=(s[layers-1],s[layers-1]),padding=p[layers-1],name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    #print(x.shape)\n",
        "\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "\n",
        "    x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"Stage 3:\", (x_skip.shape,x.shape))\n",
        "\n",
        "    return x\n",
        "  def createStageFour_(x, f,k, s,p,counter):\n",
        "    '''\n",
        "    Argument\n",
        "    x - input\n",
        "    f - filter_size\n",
        "    k - kernel size\n",
        "    s - stride\n",
        "    p - padding\n",
        "    '''\n",
        "    block_name = 'stage_4'+counter\n",
        "    x_skip = x\n",
        "    #print(\"Recevied Input at Stage 4: \", x.shape)\n",
        "    layers = len(f)\n",
        "    for i in range(layers):\n",
        "      x = Conv2D(f[i],kernel_size=(k[i],k[i]),strides=(s[i],s[i]),padding=p[i])(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "    x = Conv2D(f[layers-1],kernel_size=(k[layers-1],k[layers-1]),strides=(s[layers-1],s[layers-1]),padding=p[layers-1],name=block_name+'b')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    #print(x.shape)\n",
        "\n",
        "    if x.shape[1] != x_skip.shape[1]:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(2,2),padding='valid')(x_skip)\n",
        "    else:\n",
        "      x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "\n",
        "    x_skip = Conv2D(f[layers-1],kernel_size=(1,1),strides=(1,1),padding='valid')(x_skip)\n",
        "    x_skip = BatchNormalization()(x_skip)\n",
        "    x = Add()([x,x_skip])\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"Stage 4:\", (x_skip.shape,x.shape))\n",
        "\n",
        "    return x\n",
        "  def resnet50():\n",
        "    inputs = Input(shape = (32,32,3), name = \"image_input\")\n",
        "    x = ZeroPadding2D((3,3))(inputs)\n",
        "    # Initial Convolutional block\n",
        "    \n",
        "    x = Conv2D(64, kernel_size=(7,7), strides = (2,2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    #print(\"before Max pooling: \", x.shape)\n",
        "    x = MaxPooling2D((3,3),strides=(2,2))(x)\n",
        "    x = createStageOne(x,[64,64,256,64],[1,3,1,1],[1,1,1,1],['valid','same','valid','valid'],'1')\n",
        "    x = createStageOne(x,[64,256,64,64],[3,1,1,3],[1,1,1,1],['same','valid','valid','same'],'2')\n",
        "\n",
        "    x = createStageTwo_(x,[256,128,128,512],[1,1,3,1],[1,2,1,1],['valid','valid','same','valid'],'3')\n",
        "    x = createStageTwo_(x,[128,128,512,128],[1,3,1,1],[1,1,1,1],['valid','same','valid','valid'],'4')\n",
        "    x = createStageTwo_(x,[128,512,128,128],[3,1,1,3],[1,1,1,1],['same','valid','valid','same'],'5')\n",
        "\n",
        "    x = createStageThree_(x, [512,256,256,1024],[1,1,3,1],[1,2,1,1],['valid','valid','same','valid'],'6')\n",
        "    x = createStageThree_(x, [256,256,1024,256],[1,3,1,1],[1,1,1,1],['valid','same','valid','valid'],'7')\n",
        "    x = createStageThree_(x, [256,1024,256,256],[3,1,1,3],[1,1,1,1],['same','valid','valid','same'],'8')\n",
        "    x = createStageThree_(x, [1024,256,256,1024],[1,1,3,1],[1,1,1,1],['valid','valid','same','valid'],'9')\n",
        "\n",
        "\n",
        "    x = createStageFour_(x,[256,256,1024,512],[1,3,1,1],[1,1,1,2],['valid','same','valid','valid'],'10')\n",
        "    x = createStageFour_(x,[512,2048,512,512],[3,1,1,3],[1,1,1,1],['same','valid','valid','same'],'11')\n",
        "    x = createStageFour_(x,[2048,512,512,2048],[1,1,3,1],[1,1,1,1],['valid','valid','same','valid'],'12')\n",
        "\n",
        "    x = AveragePooling2D((2,2),padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(10,activation='softmax')(x)\n",
        "    model = Model(inputs=inputs,outputs=x, name='LResNet50')\n",
        "    #print(x.shape)\n",
        "    return model\n",
        "\n",
        "  model = resnet50()\n",
        "  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  #model.summary()\n",
        "  X_train, X_test = normalizeInput(dataTrain[i][0], dataTest[i][0])\n",
        "  y_train = dataTrain[i][1]\n",
        "  y_test = dataTest[i][1]\n",
        "  print(\"Len: \",len(X_train))\n",
        "  csvLogger = CSVLogger('/content/drive/MyDrive/PhD Studies/fall21/ADVML/results/skip4/'+str(i)+'.csv')\n",
        "  earlyStop = EarlyStopping(monitor='loss',patience=5,mode='auto')\n",
        "  history = model.fit(X_train,y_train, epochs=300,batch_size=1024,validation_data=(X_test,y_test),verbose=1,callbacks=[csvLogger,earlyStop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 64)\n",
            "(None, 7, 7, 64)\n",
            "(None, 4, 4, 512)\n",
            "(None, 4, 4, 128)\n",
            "(None, 4, 4, 128)\n",
            "Len:  10000\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 11s 387ms/step - loss: 3.3180 - accuracy: 0.1160 - val_loss: 2.3086 - val_accuracy: 0.1105\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 2.3632 - accuracy: 0.1660 - val_loss: 2.3142 - val_accuracy: 0.0990\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 2.1372 - accuracy: 0.2105 - val_loss: 2.3341 - val_accuracy: 0.0990\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 2.0069 - accuracy: 0.2446 - val_loss: 2.3912 - val_accuracy: 0.0990\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 1.9015 - accuracy: 0.2873 - val_loss: 2.4645 - val_accuracy: 0.0990\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 1.7413 - accuracy: 0.3547 - val_loss: 2.5796 - val_accuracy: 0.0990\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 1.5406 - accuracy: 0.4196 - val_loss: 2.7464 - val_accuracy: 0.1115\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 1.4089 - accuracy: 0.4731 - val_loss: 2.8835 - val_accuracy: 0.1080\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 1.2112 - accuracy: 0.5482 - val_loss: 2.8438 - val_accuracy: 0.1120\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 3s 261ms/step - loss: 1.0699 - accuracy: 0.6120 - val_loss: 3.0599 - val_accuracy: 0.1130\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.9399 - accuracy: 0.6588 - val_loss: 3.0626 - val_accuracy: 0.1145\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.7687 - accuracy: 0.7299 - val_loss: 3.0380 - val_accuracy: 0.1330\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.6906 - accuracy: 0.7587 - val_loss: 3.5071 - val_accuracy: 0.0980\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.6147 - accuracy: 0.7841 - val_loss: 3.2603 - val_accuracy: 0.1275\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.5622 - accuracy: 0.8039 - val_loss: 3.2891 - val_accuracy: 0.1380\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.4220 - accuracy: 0.8561 - val_loss: 3.1823 - val_accuracy: 0.1470\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.4112 - accuracy: 0.8574 - val_loss: 3.8532 - val_accuracy: 0.1440\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.3559 - accuracy: 0.8771 - val_loss: 3.1804 - val_accuracy: 0.1795\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.3097 - accuracy: 0.8960 - val_loss: 3.4005 - val_accuracy: 0.1955\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.3159 - accuracy: 0.8937 - val_loss: 3.0747 - val_accuracy: 0.2225\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.2936 - accuracy: 0.9007 - val_loss: 3.2426 - val_accuracy: 0.2345\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.2634 - accuracy: 0.9115 - val_loss: 3.7642 - val_accuracy: 0.2010\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.2628 - accuracy: 0.9173 - val_loss: 3.4719 - val_accuracy: 0.2405\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.2672 - accuracy: 0.9155 - val_loss: 3.3078 - val_accuracy: 0.2545\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.2001 - accuracy: 0.9353 - val_loss: 3.8158 - val_accuracy: 0.2725\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.1872 - accuracy: 0.9387 - val_loss: 3.6159 - val_accuracy: 0.3020\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.1753 - accuracy: 0.9399 - val_loss: 3.8556 - val_accuracy: 0.2910\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1616 - accuracy: 0.9451 - val_loss: 3.8667 - val_accuracy: 0.2925\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.1789 - accuracy: 0.9429 - val_loss: 3.8626 - val_accuracy: 0.3135\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1913 - accuracy: 0.9404 - val_loss: 4.2080 - val_accuracy: 0.2965\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.1838 - accuracy: 0.9410 - val_loss: 4.5207 - val_accuracy: 0.2960\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1567 - accuracy: 0.9476 - val_loss: 4.3992 - val_accuracy: 0.3185\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1448 - accuracy: 0.9526 - val_loss: 4.4932 - val_accuracy: 0.3225\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.1247 - accuracy: 0.9582 - val_loss: 4.6063 - val_accuracy: 0.3245\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1201 - accuracy: 0.9592 - val_loss: 4.6811 - val_accuracy: 0.3325\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1162 - accuracy: 0.9618 - val_loss: 4.4406 - val_accuracy: 0.3490\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1174 - accuracy: 0.9617 - val_loss: 4.6524 - val_accuracy: 0.3325\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1058 - accuracy: 0.9651 - val_loss: 4.4982 - val_accuracy: 0.3450\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1082 - accuracy: 0.9670 - val_loss: 5.1442 - val_accuracy: 0.3225\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1069 - accuracy: 0.9633 - val_loss: 4.6956 - val_accuracy: 0.3485\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.0886 - accuracy: 0.9700 - val_loss: 4.5205 - val_accuracy: 0.3560\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.0973 - accuracy: 0.9676 - val_loss: 4.5735 - val_accuracy: 0.3500\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0973 - accuracy: 0.9692 - val_loss: 4.6181 - val_accuracy: 0.3535\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0983 - accuracy: 0.9686 - val_loss: 4.5017 - val_accuracy: 0.3480\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0866 - accuracy: 0.9714 - val_loss: 4.6875 - val_accuracy: 0.3395\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0806 - accuracy: 0.9736 - val_loss: 4.7127 - val_accuracy: 0.3295\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0821 - accuracy: 0.9712 - val_loss: 5.3447 - val_accuracy: 0.3390\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.0951 - accuracy: 0.9674 - val_loss: 4.7154 - val_accuracy: 0.3485\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1069 - accuracy: 0.9655 - val_loss: 4.7786 - val_accuracy: 0.3355\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.0934 - accuracy: 0.9685 - val_loss: 4.5002 - val_accuracy: 0.3540\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.0655 - accuracy: 0.9785 - val_loss: 4.7735 - val_accuracy: 0.3510\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 4.6676 - val_accuracy: 0.3520\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0853 - accuracy: 0.9713 - val_loss: 4.7183 - val_accuracy: 0.3470\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.0868 - accuracy: 0.9712 - val_loss: 4.5553 - val_accuracy: 0.3700\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.1036 - accuracy: 0.9701 - val_loss: 4.7099 - val_accuracy: 0.3575\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.1277 - accuracy: 0.9610 - val_loss: 6.0374 - val_accuracy: 0.3485\n",
            "(None, 7, 7, 64)\n",
            "(None, 7, 7, 64)\n",
            "(None, 4, 4, 512)\n",
            "(None, 4, 4, 128)\n",
            "(None, 4, 4, 128)\n",
            "Len:  20000\n",
            "Epoch 1/300\n",
            "20/20 [==============================] - 15s 453ms/step - loss: 2.8185 - accuracy: 0.1411 - val_loss: 2.2967 - val_accuracy: 0.1060\n",
            "Epoch 2/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 2.0985 - accuracy: 0.2116 - val_loss: 2.2898 - val_accuracy: 0.1308\n",
            "Epoch 3/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.9497 - accuracy: 0.2666 - val_loss: 2.3458 - val_accuracy: 0.1233\n",
            "Epoch 4/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.8115 - accuracy: 0.3169 - val_loss: 2.4633 - val_accuracy: 0.1015\n",
            "Epoch 5/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.6771 - accuracy: 0.3691 - val_loss: 2.6161 - val_accuracy: 0.0980\n",
            "Epoch 6/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.5281 - accuracy: 0.4252 - val_loss: 2.4648 - val_accuracy: 0.1258\n",
            "Epoch 7/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.4061 - accuracy: 0.4684 - val_loss: 2.4178 - val_accuracy: 0.1465\n",
            "Epoch 8/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 1.2995 - accuracy: 0.5135 - val_loss: 2.2107 - val_accuracy: 0.1737\n",
            "Epoch 9/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.1978 - accuracy: 0.5446 - val_loss: 2.5739 - val_accuracy: 0.1565\n",
            "Epoch 10/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 1.0930 - accuracy: 0.5831 - val_loss: 2.3798 - val_accuracy: 0.2005\n",
            "Epoch 11/300\n",
            "20/20 [==============================] - 5s 260ms/step - loss: 1.0002 - accuracy: 0.6229 - val_loss: 2.5692 - val_accuracy: 0.2050\n",
            "Epoch 12/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.9469 - accuracy: 0.6437 - val_loss: 3.3863 - val_accuracy: 0.1698\n",
            "Epoch 13/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.8576 - accuracy: 0.6783 - val_loss: 2.8083 - val_accuracy: 0.2315\n",
            "Epoch 14/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.7740 - accuracy: 0.7100 - val_loss: 2.5415 - val_accuracy: 0.2822\n",
            "Epoch 15/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.7446 - accuracy: 0.7278 - val_loss: 3.0602 - val_accuracy: 0.2792\n",
            "Epoch 16/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.6884 - accuracy: 0.7502 - val_loss: 2.9636 - val_accuracy: 0.3178\n",
            "Epoch 17/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.6370 - accuracy: 0.7664 - val_loss: 3.3384 - val_accuracy: 0.3133\n",
            "Epoch 18/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.5918 - accuracy: 0.7868 - val_loss: 3.1230 - val_accuracy: 0.3298\n",
            "Epoch 19/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.5599 - accuracy: 0.7973 - val_loss: 3.5047 - val_accuracy: 0.3408\n",
            "Epoch 20/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.5019 - accuracy: 0.8190 - val_loss: 3.6972 - val_accuracy: 0.3402\n",
            "Epoch 21/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.4646 - accuracy: 0.8340 - val_loss: 4.0139 - val_accuracy: 0.3145\n",
            "Epoch 22/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.4153 - accuracy: 0.8507 - val_loss: 4.0455 - val_accuracy: 0.3413\n",
            "Epoch 23/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.3976 - accuracy: 0.8597 - val_loss: 3.6340 - val_accuracy: 0.3607\n",
            "Epoch 24/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.3725 - accuracy: 0.8702 - val_loss: 3.6555 - val_accuracy: 0.3765\n",
            "Epoch 25/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.3279 - accuracy: 0.8831 - val_loss: 3.8595 - val_accuracy: 0.3742\n",
            "Epoch 26/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.3112 - accuracy: 0.8906 - val_loss: 3.7933 - val_accuracy: 0.3860\n",
            "Epoch 27/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.3122 - accuracy: 0.8899 - val_loss: 4.1185 - val_accuracy: 0.3810\n",
            "Epoch 28/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2721 - accuracy: 0.9043 - val_loss: 3.8910 - val_accuracy: 0.3890\n",
            "Epoch 29/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2559 - accuracy: 0.9116 - val_loss: 3.9546 - val_accuracy: 0.3728\n",
            "Epoch 30/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2831 - accuracy: 0.9028 - val_loss: 4.1647 - val_accuracy: 0.3803\n",
            "Epoch 31/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2457 - accuracy: 0.9141 - val_loss: 4.1503 - val_accuracy: 0.3817\n",
            "Epoch 32/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2301 - accuracy: 0.9187 - val_loss: 3.9767 - val_accuracy: 0.3668\n",
            "Epoch 33/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2245 - accuracy: 0.9210 - val_loss: 4.2725 - val_accuracy: 0.3532\n",
            "Epoch 34/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1950 - accuracy: 0.9322 - val_loss: 4.3112 - val_accuracy: 0.3735\n",
            "Epoch 35/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.2082 - accuracy: 0.9294 - val_loss: 4.0819 - val_accuracy: 0.3750\n",
            "Epoch 36/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1783 - accuracy: 0.9378 - val_loss: 4.3446 - val_accuracy: 0.3778\n",
            "Epoch 37/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1725 - accuracy: 0.9397 - val_loss: 4.1496 - val_accuracy: 0.3850\n",
            "Epoch 38/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.1567 - accuracy: 0.9470 - val_loss: 4.4523 - val_accuracy: 0.3585\n",
            "Epoch 39/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1764 - accuracy: 0.9385 - val_loss: 4.3425 - val_accuracy: 0.3733\n",
            "Epoch 40/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1650 - accuracy: 0.9439 - val_loss: 3.9254 - val_accuracy: 0.3873\n",
            "Epoch 41/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1480 - accuracy: 0.9488 - val_loss: 4.1983 - val_accuracy: 0.3900\n",
            "Epoch 42/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.1419 - accuracy: 0.9513 - val_loss: 4.0634 - val_accuracy: 0.3938\n",
            "Epoch 43/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1627 - accuracy: 0.9439 - val_loss: 3.8196 - val_accuracy: 0.3983\n",
            "Epoch 44/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1539 - accuracy: 0.9473 - val_loss: 3.9197 - val_accuracy: 0.3968\n",
            "Epoch 45/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1542 - accuracy: 0.9466 - val_loss: 3.8842 - val_accuracy: 0.3907\n",
            "Epoch 46/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1364 - accuracy: 0.9505 - val_loss: 4.1103 - val_accuracy: 0.3947\n",
            "Epoch 47/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1276 - accuracy: 0.9571 - val_loss: 3.8393 - val_accuracy: 0.4173\n",
            "Epoch 48/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1106 - accuracy: 0.9624 - val_loss: 4.1547 - val_accuracy: 0.4110\n",
            "Epoch 49/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1271 - accuracy: 0.9575 - val_loss: 3.9918 - val_accuracy: 0.4083\n",
            "Epoch 50/300\n",
            "20/20 [==============================] - 5s 260ms/step - loss: 0.1346 - accuracy: 0.9530 - val_loss: 3.9887 - val_accuracy: 0.4223\n",
            "Epoch 51/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1254 - accuracy: 0.9571 - val_loss: 3.9600 - val_accuracy: 0.4103\n",
            "Epoch 52/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1147 - accuracy: 0.9592 - val_loss: 4.2575 - val_accuracy: 0.3943\n",
            "Epoch 53/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1025 - accuracy: 0.9651 - val_loss: 3.9947 - val_accuracy: 0.4047\n",
            "Epoch 54/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.1182 - accuracy: 0.9597 - val_loss: 4.0764 - val_accuracy: 0.3977\n",
            "Epoch 55/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1269 - accuracy: 0.9570 - val_loss: 3.8491 - val_accuracy: 0.4047\n",
            "Epoch 56/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.0923 - accuracy: 0.9690 - val_loss: 4.0170 - val_accuracy: 0.4190\n",
            "Epoch 57/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.1072 - accuracy: 0.9630 - val_loss: 4.1907 - val_accuracy: 0.4098\n",
            "Epoch 58/300\n",
            "20/20 [==============================] - 5s 260ms/step - loss: 0.1311 - accuracy: 0.9546 - val_loss: 3.8698 - val_accuracy: 0.4087\n",
            "Epoch 59/300\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 0.1128 - accuracy: 0.9621 - val_loss: 3.8929 - val_accuracy: 0.4153\n",
            "Epoch 60/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.0957 - accuracy: 0.9681 - val_loss: 4.0985 - val_accuracy: 0.3988\n",
            "Epoch 61/300\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 0.0963 - accuracy: 0.9678 - val_loss: 4.0033 - val_accuracy: 0.4105\n",
            "(None, 7, 7, 64)\n",
            "(None, 7, 7, 64)\n",
            "(None, 4, 4, 512)\n",
            "(None, 4, 4, 128)\n",
            "(None, 4, 4, 128)\n",
            "Len:  30000\n",
            "Epoch 1/300\n",
            "30/30 [==============================] - 18s 368ms/step - loss: 2.6098 - accuracy: 0.1511 - val_loss: 2.3335 - val_accuracy: 0.1043\n",
            "Epoch 2/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 2.0553 - accuracy: 0.2258 - val_loss: 2.3754 - val_accuracy: 0.1108\n",
            "Epoch 3/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 1.8800 - accuracy: 0.3006 - val_loss: 2.4289 - val_accuracy: 0.1005\n",
            "Epoch 4/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 1.7208 - accuracy: 0.3636 - val_loss: 2.4907 - val_accuracy: 0.1005\n",
            "Epoch 5/300\n",
            "30/30 [==============================] - 8s 259ms/step - loss: 1.5711 - accuracy: 0.4235 - val_loss: 2.6833 - val_accuracy: 0.1005\n",
            "Epoch 6/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 1.4328 - accuracy: 0.4760 - val_loss: 2.8264 - val_accuracy: 0.1073\n",
            "Epoch 7/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 1.3318 - accuracy: 0.5135 - val_loss: 3.4290 - val_accuracy: 0.1138\n",
            "Epoch 8/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 1.2502 - accuracy: 0.5460 - val_loss: 3.0563 - val_accuracy: 0.1540\n",
            "Epoch 9/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 1.1214 - accuracy: 0.5948 - val_loss: 3.0597 - val_accuracy: 0.2145\n",
            "Epoch 10/300\n",
            "30/30 [==============================] - 8s 257ms/step - loss: 1.0577 - accuracy: 0.6199 - val_loss: 3.4835 - val_accuracy: 0.2260\n",
            "Epoch 11/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.9800 - accuracy: 0.6516 - val_loss: 2.7418 - val_accuracy: 0.3033\n",
            "Epoch 12/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.9098 - accuracy: 0.6727 - val_loss: 2.8044 - val_accuracy: 0.3373\n",
            "Epoch 13/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.8455 - accuracy: 0.6972 - val_loss: 2.7129 - val_accuracy: 0.3670\n",
            "Epoch 14/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.8037 - accuracy: 0.7148 - val_loss: 2.8077 - val_accuracy: 0.3770\n",
            "Epoch 15/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.8078 - accuracy: 0.7242 - val_loss: 5.6952 - val_accuracy: 0.3160\n",
            "Epoch 16/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.7777 - accuracy: 0.7328 - val_loss: 3.7360 - val_accuracy: 0.3515\n",
            "Epoch 17/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.7413 - accuracy: 0.7445 - val_loss: 3.0217 - val_accuracy: 0.3965\n",
            "Epoch 18/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.6659 - accuracy: 0.7734 - val_loss: 3.1464 - val_accuracy: 0.3777\n",
            "Epoch 19/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.6217 - accuracy: 0.7885 - val_loss: 3.2250 - val_accuracy: 0.3990\n",
            "Epoch 20/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.5282 - accuracy: 0.8193 - val_loss: 3.4340 - val_accuracy: 0.3993\n",
            "Epoch 21/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.5448 - accuracy: 0.8175 - val_loss: 2.9997 - val_accuracy: 0.4045\n",
            "Epoch 22/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.5315 - accuracy: 0.8286 - val_loss: 11.6358 - val_accuracy: 0.3757\n",
            "Epoch 23/300\n",
            "30/30 [==============================] - 8s 259ms/step - loss: 0.5286 - accuracy: 0.8307 - val_loss: 3.1945 - val_accuracy: 0.4087\n",
            "Epoch 24/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.4207 - accuracy: 0.8658 - val_loss: 3.3395 - val_accuracy: 0.4190\n",
            "Epoch 25/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.4740 - accuracy: 0.8482 - val_loss: 3.4735 - val_accuracy: 0.3895\n",
            "Epoch 26/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.5969 - accuracy: 0.8028 - val_loss: 7.1802 - val_accuracy: 0.3727\n",
            "Epoch 27/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.5269 - accuracy: 0.8198 - val_loss: 3.1726 - val_accuracy: 0.4103\n",
            "Epoch 28/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.4894 - accuracy: 0.8362 - val_loss: 3.3891 - val_accuracy: 0.3772\n",
            "Epoch 29/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.4015 - accuracy: 0.8684 - val_loss: 3.0327 - val_accuracy: 0.4275\n",
            "Epoch 30/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.3133 - accuracy: 0.8969 - val_loss: 3.1765 - val_accuracy: 0.4382\n",
            "Epoch 31/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.3166 - accuracy: 0.9006 - val_loss: 3.6365 - val_accuracy: 0.3935\n",
            "Epoch 32/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.3687 - accuracy: 0.8760 - val_loss: 2.9627 - val_accuracy: 0.4243\n",
            "Epoch 33/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.7353 - accuracy: 0.7470 - val_loss: 375.8281 - val_accuracy: 0.3157\n",
            "Epoch 34/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.8351 - accuracy: 0.7098 - val_loss: 101.8859 - val_accuracy: 0.3575\n",
            "Epoch 35/300\n",
            "30/30 [==============================] - 8s 258ms/step - loss: 0.4128 - accuracy: 0.8591 - val_loss: 5.7569 - val_accuracy: 0.4397\n",
            "(None, 7, 7, 64)\n",
            "(None, 7, 7, 64)\n",
            "(None, 4, 4, 512)\n",
            "(None, 4, 4, 128)\n",
            "(None, 4, 4, 128)\n",
            "Len:  40000\n",
            "Epoch 1/300\n",
            "40/40 [==============================] - 20s 319ms/step - loss: 2.4758 - accuracy: 0.1902 - val_loss: 2.4397 - val_accuracy: 0.0986\n",
            "Epoch 2/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.9409 - accuracy: 0.2784 - val_loss: 2.5908 - val_accuracy: 0.1051\n",
            "Epoch 3/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.7832 - accuracy: 0.3449 - val_loss: 2.6606 - val_accuracy: 0.1034\n",
            "Epoch 4/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.6517 - accuracy: 0.3979 - val_loss: 2.8085 - val_accuracy: 0.1195\n",
            "Epoch 5/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.5149 - accuracy: 0.4508 - val_loss: 2.6849 - val_accuracy: 0.1659\n",
            "Epoch 6/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.4208 - accuracy: 0.4888 - val_loss: 2.8618 - val_accuracy: 0.1735\n",
            "Epoch 7/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.3498 - accuracy: 0.5127 - val_loss: 2.7783 - val_accuracy: 0.2254\n",
            "Epoch 8/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.2426 - accuracy: 0.5549 - val_loss: 2.2003 - val_accuracy: 0.3433\n",
            "Epoch 9/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.1962 - accuracy: 0.5728 - val_loss: 2.1977 - val_accuracy: 0.3523\n",
            "Epoch 10/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.2196 - accuracy: 0.5717 - val_loss: 2.0190 - val_accuracy: 0.3860\n",
            "Epoch 11/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.2519 - accuracy: 0.5562 - val_loss: 2.1125 - val_accuracy: 0.4165\n",
            "Epoch 12/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.0927 - accuracy: 0.6118 - val_loss: 2.0222 - val_accuracy: 0.4300\n",
            "Epoch 13/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.0224 - accuracy: 0.6379 - val_loss: 2.3671 - val_accuracy: 0.4161\n",
            "Epoch 14/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.9228 - accuracy: 0.6730 - val_loss: 2.3311 - val_accuracy: 0.4256\n",
            "Epoch 15/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.9331 - accuracy: 0.6707 - val_loss: 2.2261 - val_accuracy: 0.4380\n",
            "Epoch 16/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.9256 - accuracy: 0.6736 - val_loss: 2.3371 - val_accuracy: 0.4500\n",
            "Epoch 17/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.7983 - accuracy: 0.7199 - val_loss: 2.4673 - val_accuracy: 0.4075\n",
            "Epoch 18/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.4194 - accuracy: 0.5043 - val_loss: 289.1654 - val_accuracy: 0.1329\n",
            "Epoch 19/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 1.1876 - accuracy: 0.5753 - val_loss: 2.4001 - val_accuracy: 0.4150\n",
            "Epoch 20/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.9890 - accuracy: 0.6541 - val_loss: 2.2364 - val_accuracy: 0.4534\n",
            "Epoch 21/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.8921 - accuracy: 0.6870 - val_loss: 1.8726 - val_accuracy: 0.4767\n",
            "Epoch 22/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.7499 - accuracy: 0.7392 - val_loss: 2.0875 - val_accuracy: 0.4605\n",
            "Epoch 23/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.6694 - accuracy: 0.7683 - val_loss: 2.4340 - val_accuracy: 0.4569\n",
            "Epoch 24/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.6870 - accuracy: 0.7642 - val_loss: 2.2675 - val_accuracy: 0.4586\n",
            "Epoch 25/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.6701 - accuracy: 0.7703 - val_loss: 2.2720 - val_accuracy: 0.4671\n",
            "Epoch 26/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.6212 - accuracy: 0.7851 - val_loss: 2.2891 - val_accuracy: 0.4741\n",
            "Epoch 27/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.5712 - accuracy: 0.8067 - val_loss: 30.8320 - val_accuracy: 0.3966\n",
            "Epoch 28/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 1.1567 - accuracy: 0.6086 - val_loss: 1249.0438 - val_accuracy: 0.1775\n",
            "Epoch 29/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.8090 - accuracy: 0.7203 - val_loss: 2.7085 - val_accuracy: 0.4815\n",
            "Epoch 30/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.6304 - accuracy: 0.7848 - val_loss: 2.2661 - val_accuracy: 0.5048\n",
            "Epoch 31/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.5561 - accuracy: 0.8098 - val_loss: 2.6617 - val_accuracy: 0.4794\n",
            "Epoch 32/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.5240 - accuracy: 0.8188 - val_loss: 2.4791 - val_accuracy: 0.4902\n",
            "Epoch 33/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.4134 - accuracy: 0.8588 - val_loss: 2.5333 - val_accuracy: 0.4901\n",
            "Epoch 34/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.3676 - accuracy: 0.8769 - val_loss: 2.4830 - val_accuracy: 0.4900\n",
            "Epoch 35/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.4711 - accuracy: 0.8384 - val_loss: 2.4717 - val_accuracy: 0.5060\n",
            "Epoch 36/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.3502 - accuracy: 0.8882 - val_loss: 2.7091 - val_accuracy: 0.4905\n",
            "Epoch 37/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.3887 - accuracy: 0.8682 - val_loss: 2.6868 - val_accuracy: 0.4925\n",
            "Epoch 38/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.3572 - accuracy: 0.8780 - val_loss: 2.4482 - val_accuracy: 0.5058\n",
            "Epoch 39/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.3514 - accuracy: 0.8774 - val_loss: 2.6611 - val_accuracy: 0.5017\n",
            "Epoch 40/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.3424 - accuracy: 0.8850 - val_loss: 2.5705 - val_accuracy: 0.5059\n",
            "Epoch 41/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.4487 - accuracy: 0.8569 - val_loss: 2.3948 - val_accuracy: 0.4976\n",
            "Epoch 42/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.3643 - accuracy: 0.8787 - val_loss: 2.5374 - val_accuracy: 0.4960\n",
            "Epoch 43/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.4696 - accuracy: 0.8407 - val_loss: 2.5093 - val_accuracy: 0.5086\n",
            "Epoch 44/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.3150 - accuracy: 0.8922 - val_loss: 2.6688 - val_accuracy: 0.5100\n",
            "Epoch 45/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.3627 - accuracy: 0.8743 - val_loss: 2.6912 - val_accuracy: 0.5011\n",
            "Epoch 46/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.3068 - accuracy: 0.8936 - val_loss: 2.8308 - val_accuracy: 0.5030\n",
            "Epoch 47/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.2358 - accuracy: 0.9196 - val_loss: 2.7560 - val_accuracy: 0.5016\n",
            "Epoch 48/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.2565 - accuracy: 0.9113 - val_loss: 2.5963 - val_accuracy: 0.5311\n",
            "Epoch 49/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.1819 - accuracy: 0.9394 - val_loss: 3.8928 - val_accuracy: 0.4074\n",
            "Epoch 50/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 1.8950 - accuracy: 0.3805 - val_loss: 247.9397 - val_accuracy: 0.0569\n",
            "Epoch 51/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 1.6702 - accuracy: 0.3911 - val_loss: 715.9012 - val_accuracy: 0.1130\n",
            "Epoch 52/300\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 1.4949 - accuracy: 0.4459 - val_loss: 234.7240 - val_accuracy: 0.2491\n",
            "Epoch 53/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 1.3283 - accuracy: 0.5144 - val_loss: 4.9157 - val_accuracy: 0.4038\n",
            "Epoch 54/300\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 1.2403 - accuracy: 0.5565 - val_loss: 1.5799 - val_accuracy: 0.4773\n",
            "(None, 7, 7, 64)\n",
            "(None, 7, 7, 64)\n",
            "(None, 4, 4, 512)\n",
            "(None, 4, 4, 128)\n",
            "(None, 4, 4, 128)\n",
            "Len:  50000\n",
            "Epoch 1/300\n",
            "49/49 [==============================] - 24s 335ms/step - loss: 2.4134 - accuracy: 0.1834 - val_loss: 2.3048 - val_accuracy: 0.1162\n",
            "Epoch 2/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.8998 - accuracy: 0.2944 - val_loss: 2.2590 - val_accuracy: 0.1060\n",
            "Epoch 3/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.7061 - accuracy: 0.3695 - val_loss: 2.1975 - val_accuracy: 0.1867\n",
            "Epoch 4/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.5484 - accuracy: 0.4339 - val_loss: 2.1492 - val_accuracy: 0.2251\n",
            "Epoch 5/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.4123 - accuracy: 0.4851 - val_loss: 2.6227 - val_accuracy: 0.2182\n",
            "Epoch 6/300\n",
            "49/49 [==============================] - 13s 261ms/step - loss: 1.3000 - accuracy: 0.5277 - val_loss: 2.5577 - val_accuracy: 0.2622\n",
            "Epoch 7/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.1957 - accuracy: 0.5681 - val_loss: 1.9288 - val_accuracy: 0.3685\n",
            "Epoch 8/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.1200 - accuracy: 0.5988 - val_loss: 2.2909 - val_accuracy: 0.3681\n",
            "Epoch 9/300\n",
            "49/49 [==============================] - 13s 261ms/step - loss: 1.0926 - accuracy: 0.6104 - val_loss: 2.0072 - val_accuracy: 0.4217\n",
            "Epoch 10/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.0087 - accuracy: 0.6432 - val_loss: 1.9887 - val_accuracy: 0.4510\n",
            "Epoch 11/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.0589 - accuracy: 0.6301 - val_loss: 3.0164 - val_accuracy: 0.2729\n",
            "Epoch 12/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.4973 - accuracy: 0.4668 - val_loss: 44.1456 - val_accuracy: 0.2217\n",
            "Epoch 13/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.2737 - accuracy: 0.5418 - val_loss: 2.5323 - val_accuracy: 0.4333\n",
            "Epoch 14/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 1.0862 - accuracy: 0.6167 - val_loss: 1.6856 - val_accuracy: 0.4882\n",
            "Epoch 15/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.9144 - accuracy: 0.6779 - val_loss: 1.9156 - val_accuracy: 0.4832\n",
            "Epoch 16/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.8076 - accuracy: 0.7198 - val_loss: 1.9112 - val_accuracy: 0.4870\n",
            "Epoch 17/300\n",
            "49/49 [==============================] - 13s 261ms/step - loss: 0.7383 - accuracy: 0.7415 - val_loss: 2.0833 - val_accuracy: 0.4810\n",
            "Epoch 18/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.6555 - accuracy: 0.7739 - val_loss: 2.1762 - val_accuracy: 0.4863\n",
            "Epoch 19/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.6199 - accuracy: 0.7856 - val_loss: 2.3260 - val_accuracy: 0.4917\n",
            "Epoch 20/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.5577 - accuracy: 0.8092 - val_loss: 2.1792 - val_accuracy: 0.4908\n",
            "Epoch 21/300\n",
            "49/49 [==============================] - 13s 261ms/step - loss: 0.4860 - accuracy: 0.8296 - val_loss: 2.4724 - val_accuracy: 0.5001\n",
            "Epoch 22/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.4600 - accuracy: 0.8394 - val_loss: 2.2854 - val_accuracy: 0.4964\n",
            "Epoch 23/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.4091 - accuracy: 0.8595 - val_loss: 2.6744 - val_accuracy: 0.4858\n",
            "Epoch 24/300\n",
            "49/49 [==============================] - 13s 261ms/step - loss: 0.3621 - accuracy: 0.8743 - val_loss: 2.4378 - val_accuracy: 0.4989\n",
            "Epoch 25/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.3336 - accuracy: 0.8837 - val_loss: 2.5196 - val_accuracy: 0.4966\n",
            "Epoch 26/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.3128 - accuracy: 0.8909 - val_loss: 2.6842 - val_accuracy: 0.4977\n",
            "Epoch 27/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.3021 - accuracy: 0.8952 - val_loss: 2.6028 - val_accuracy: 0.5149\n",
            "Epoch 28/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2758 - accuracy: 0.9042 - val_loss: 2.4245 - val_accuracy: 0.5205\n",
            "Epoch 29/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2687 - accuracy: 0.9069 - val_loss: 2.5384 - val_accuracy: 0.5045\n",
            "Epoch 30/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2530 - accuracy: 0.9119 - val_loss: 2.6885 - val_accuracy: 0.5105\n",
            "Epoch 31/300\n",
            "49/49 [==============================] - 13s 261ms/step - loss: 0.2305 - accuracy: 0.9203 - val_loss: 2.6582 - val_accuracy: 0.5150\n",
            "Epoch 32/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2256 - accuracy: 0.9205 - val_loss: 2.7082 - val_accuracy: 0.5131\n",
            "Epoch 33/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2061 - accuracy: 0.9279 - val_loss: 2.7753 - val_accuracy: 0.5210\n",
            "Epoch 34/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1959 - accuracy: 0.9334 - val_loss: 2.8492 - val_accuracy: 0.5067\n",
            "Epoch 35/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2065 - accuracy: 0.9296 - val_loss: 2.7283 - val_accuracy: 0.5122\n",
            "Epoch 36/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.2491 - accuracy: 0.9127 - val_loss: 2.8776 - val_accuracy: 0.4947\n",
            "Epoch 37/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1985 - accuracy: 0.9326 - val_loss: 2.9202 - val_accuracy: 0.5130\n",
            "Epoch 38/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1672 - accuracy: 0.9429 - val_loss: 2.7881 - val_accuracy: 0.5081\n",
            "Epoch 39/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1577 - accuracy: 0.9444 - val_loss: 3.0510 - val_accuracy: 0.5230\n",
            "Epoch 40/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1478 - accuracy: 0.9488 - val_loss: 2.5621 - val_accuracy: 0.5244\n",
            "Epoch 41/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1511 - accuracy: 0.9477 - val_loss: 2.7489 - val_accuracy: 0.5305\n",
            "Epoch 42/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1462 - accuracy: 0.9510 - val_loss: 2.7902 - val_accuracy: 0.5368\n",
            "Epoch 43/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1450 - accuracy: 0.9499 - val_loss: 2.6941 - val_accuracy: 0.5257\n",
            "Epoch 44/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1400 - accuracy: 0.9517 - val_loss: 2.5577 - val_accuracy: 0.5324\n",
            "Epoch 45/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1382 - accuracy: 0.9519 - val_loss: 2.6075 - val_accuracy: 0.5414\n",
            "Epoch 46/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1243 - accuracy: 0.9583 - val_loss: 2.8122 - val_accuracy: 0.5388\n",
            "Epoch 47/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1235 - accuracy: 0.9569 - val_loss: 2.7596 - val_accuracy: 0.5230\n",
            "Epoch 48/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1284 - accuracy: 0.9557 - val_loss: 3.0369 - val_accuracy: 0.5099\n",
            "Epoch 49/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.1473 - accuracy: 0.9506 - val_loss: 2.7799 - val_accuracy: 0.5060\n",
            "Epoch 50/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.4046 - accuracy: 0.8744 - val_loss: 2.7375 - val_accuracy: 0.4709\n",
            "Epoch 51/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.8455 - accuracy: 0.7179 - val_loss: 53.1094 - val_accuracy: 0.1337\n",
            "Epoch 52/300\n",
            "49/49 [==============================] - 13s 262ms/step - loss: 0.5269 - accuracy: 0.8225 - val_loss: 2.5547 - val_accuracy: 0.5166\n"
          ]
        }
      ]
    }
  ]
}